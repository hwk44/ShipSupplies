{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7086ce99-9df3-4913-b02f-a17ad937d3dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../data/raw_postpro.csv', encoding = 'cp949')\n",
    "# 컬럼 삭제\n",
    "df = data.drop(['Part No.2', '미입고 기간', '선박입고','완료 여부'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b4538c-2a22-42b5-90a3-3a145328329e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "y = df['key2']\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = y.values.ravel()  # y를 1차원 배열로 변환\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7cef723-3ec9-4a47-a6e0-bd8fc88491fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoders = {}  # 각 열에 대한 LabelEncoder를 저장하기 위한 딕셔너리\n",
    "columns_to_encode = [\"Subject\",'Machinery', 'Assembly' , \"Part No.1\",\"청구품목\", 'key2']  # 인코딩을 수행할 열의 이름 리스트\n",
    "\n",
    "for column in columns_to_encode:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df[column])\n",
    "    label_encoders[column] = le # 딕셔너리에 저장\n",
    "    df[column+\"_encoded\"] = le.transform(df[column]) # 새로운 encoding 된 컬럼 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd60d4d-36f9-4e00-bdd5-6f94c582fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩된 컬럼을 사용\n",
    "encoded_columns = ['Subject_encoded','Machinery_encoded', 'Assembly_encoded', 'Part No.1_encoded', '청구품목_encoded']\n",
    "X = df[encoded_columns].values\n",
    "y = df['key2_encoded'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "325ee4e8-ee44-4de9-bff6-69b1818787e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 940,  108,  281, 5759, 4848],\n",
       "        [1647,  113, 1180, 5759, 3692],\n",
       "        [1648,  113,  206, 5759, 5915],\n",
       "        ...,\n",
       "        [ 568,    0,  900, 8123, 4151],\n",
       "        [ 233,    4, 1210, 8124, 1592],\n",
       "        [ 233,    4, 1210, 8125, 4718]]),\n",
       " array([18, 18, 18, ...,  5, 20, 20]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e54ab9-8374-4db2-9f64-b67634899706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 학습용과 검증용으로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c3fd0f-4601-454c-8f5d-d3941dc614f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (16413, 5)\n",
      "y_train shape: (16413,)\n",
      "(16413, 5)\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(X_train.shape)\n",
    "print(X_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8127429-a4ab-4b2a-a78f-727f27d695ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Embedding, Dense, concatenate, Flatten\n",
    "\n",
    "embedding_input_dim_1 = int(np.max(X_train[:, 0])) + 2\n",
    "embedding_input_dim_2 = int(np.max(X_train[:, 1])) + 2\n",
    "embedding_input_dim_3 = int(np.max(X_train[:, 2])) + 2 # Xtrain 길이가 Xtest 보다 더 길어야 하므로 읨의 조정\n",
    "embedding_input_dim_4 = int(np.max(X_train[:, 3])) + 2\n",
    "embedding_input_dim_5 = int(np.max(X_train[:, 4])) + 2\n",
    "\n",
    "# 임베딩 설정\n",
    "embedding_dim = 8\n",
    "\n",
    "# 입력 정의\n",
    "input1 = Input(shape=(1,), dtype=\"int32\", name=\"Subject_Input\")\n",
    "input2 = Input(shape=(1,), dtype=\"int32\", name=\"Machinery_Input\")\n",
    "input3 = Input(shape=(1,), dtype=\"int32\", name=\"Assembly_Input\")\n",
    "input4 = Input(shape=(1,), dtype=\"int32\", name=\"Part_No.1_Input\")\n",
    "input5 = Input(shape=(1,), dtype=\"int32\", name=\"청구품목_Input\")\n",
    "\n",
    "\n",
    "# input1 = Input(shape=(1,), name=\"Assembly_Input\")\n",
    "# input2 = Input(shape=(1,), name=\"Resource_Input\")\n",
    "# input3 = Input(shape=(1,), name=\"Method_Input\")\n",
    "# input4 = Input(shape=(1,), name=\"Dwg_Input\")\n",
    "\n",
    "\n",
    "embedding1 = Embedding(embedding_input_dim_1, embedding_dim, name=\"Subject_Embedding\")(input1)\n",
    "embedding2 = Embedding(embedding_input_dim_2, embedding_dim, name=\"Assembly_Embedding\")(input2)\n",
    "embedding3 = Embedding(embedding_input_dim_3, embedding_dim, name=\"Resource_Embedding\")(input3)\n",
    "embedding4 = Embedding(embedding_input_dim_4, embedding_dim, name=\"Method_Embedding\")(input4)\n",
    "embedding5 = Embedding(embedding_input_dim_5, embedding_dim, name=\"Dwg_Embedding\")(input5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6830b5b5-7562-4ae5-bd9d-db78beb0f0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95f7f737-3e22-4c6d-a930-a9aacb5f26f9",
   "metadata": {},
   "source": [
    "# model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40211290-1203-43a9-98d1-cbd722fb9d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Embedding, Dense, concatenate, Flatten\n",
    "\n",
    "# # 출력 통합\n",
    "# merged_output = concatenate([embedding1, embedding2, embedding3, embedding4, embedding5], axis=-1)\n",
    "\n",
    "# # Dense 계층\n",
    "# dense_output = Dense(1, activation='sigmoid', name='Dense_output')(merged_output)\n",
    "# output = Flatten()(dense_output)\n",
    "\n",
    "# prediction = Dense(61, activation='softmax', name=\"Prediction_output\")(output)\n",
    "# # 모델 생성\n",
    "# model1 = Model(inputs=[input1, input2, input3, input4, input5], outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ab90428-9d44-40e2-8947-9ce75092d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "# # 모델 컴파일\n",
    "# learning_rate = 0.001  # 원하는 학습률 값 설정하기\n",
    "# optimizer = Adam(learning_rate=learning_rate)\n",
    "# # 모델 컴파일\n",
    "# model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "023dd884-7a41-40f7-a82e-c84d495fd7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical\n",
    "# y_train_categorical = to_categorical(y_train, num_classes=61)\n",
    "# y_test_categorical = to_categorical(y_test, num_classes=61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "778afc8a-b79d-40e8-a154-4eb086a783da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 훈련 및 콜백 설정\n",
    "# model1.fit([X_train[:, 0], X_train[:, 1], X_train[:, 2], X_train[:, 3],  X_train[:, 4]], y_train_categorical, epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "808cee95-f81e-488d-a976-f7e4806236c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred1 = model1.predict([X_test[:, 0], X_test[:, 1], X_test[:, 2], X_test[:, 3], X_test[:, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fc55a88-29b3-4261-8a64-b16d345d49ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_classes1 = np.argmax(y_pred1, axis=1)\n",
    "# # 정답과 비교할 때 카테고리화 된 y_test 필요\n",
    "# y_test_classes1 = np.argmax(y_test_categorical, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69122062-9e38-4a23-8e76-20a3a4c6c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_classes1,y_test_classes1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c1fe5a9-c801-48b4-aa0d-5bba1e9b3ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 정확도 계산\n",
    "# correct = np.sum(y_pred_classes1 == y_test_classes1)\n",
    "# accuracy = correct / y_test_classes1.shape[0]\n",
    "\n",
    "# print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "907d372b-dba4-42b2-83cb-209ef6fc14a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "# f1 = f1_score(y_test_classes1, y_pred_classes1, average='weighted')\n",
    "# print(\"F1 Score: {:.2f}%\".format(f1 * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d8f26a-63a7-48c3-8d62-72ef5404ff8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb93a13f-8657-4888-ad2b-4eccf487cb49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6913fc59-68b4-4b61-9ede-0c24e174ea9a",
   "metadata": {},
   "source": [
    "# model2 : model1 + lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e8bfe09-c4f5-491a-a3fd-5c45fcf60015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dense,Input, Embedding, concatenate, Flatten\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "merged_output = concatenate([embedding1, embedding2, embedding3, embedding4,embedding5], axis=-1)\n",
    "lstm_output = LSTM(128)(merged_output)\n",
    "\n",
    "dense_output = Dense(64, activation='relu', name='Dense_output')(lstm_output)\n",
    "prediction = Dense(61, activation='softmax', name=\"Prediction_output\")(dense_output)\n",
    "\n",
    "model2 = Model(inputs=[input1, input2, input3, input4, input5], outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db98d3de-c32b-48b7-9b91-0c1f71486218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Subject_Input (InputLayer)     [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Machinery_Input (InputLayer)   [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Assembly_Input (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Part_No.1_Input (InputLayer)   [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " 청구품목_Input (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Subject_Embedding (Embedding)  (None, 1, 8)         13736       ['Subject_Input[0][0]']          \n",
      "                                                                                                  \n",
      " Assembly_Embedding (Embedding)  (None, 1, 8)        1400        ['Machinery_Input[0][0]']        \n",
      "                                                                                                  \n",
      " Resource_Embedding (Embedding)  (None, 1, 8)        13472       ['Assembly_Input[0][0]']         \n",
      "                                                                                                  \n",
      " Method_Embedding (Embedding)   (None, 1, 8)         65024       ['Part_No.1_Input[0][0]']        \n",
      "                                                                                                  \n",
      " Dwg_Embedding (Embedding)      (None, 1, 8)         49040       ['청구품목_Input[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1, 40)        0           ['Subject_Embedding[0][0]',      \n",
      "                                                                  'Assembly_Embedding[0][0]',     \n",
      "                                                                  'Resource_Embedding[0][0]',     \n",
      "                                                                  'Method_Embedding[0][0]',       \n",
      "                                                                  'Dwg_Embedding[0][0]']          \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 128)          86528       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " Dense_output (Dense)           (None, 64)           8256        ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " Prediction_output (Dense)      (None, 61)           3965        ['Dense_output[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 241,421\n",
      "Trainable params: 241,421\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "# 모델 컴파일\n",
    "learning_rate = 0.001  # 원하는 학습률 값 설정하기\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "# 모델 컴파일\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e12be768-ea44-476e-bda6-6b63bac869c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_categorical = to_categorical(y_train, num_classes=61)\n",
    "y_test_categorical = to_categorical(y_test, num_classes=61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7868dc6-df9f-42b5-92d5-3861f8ff761b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "257/257 [==============================] - 3s 2ms/step - loss: 3.2734 - accuracy: 0.1975\n",
      "Epoch 2/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.4324 - accuracy: 0.2987\n",
      "Epoch 3/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.6592 - accuracy: 0.5184\n",
      "Epoch 4/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.0723 - accuracy: 0.6962\n",
      "Epoch 5/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.6590 - accuracy: 0.8192\n",
      "Epoch 6/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.4031 - accuracy: 0.8902\n",
      "Epoch 7/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.2416 - accuracy: 0.9326\n",
      "Epoch 8/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.1449 - accuracy: 0.9620\n",
      "Epoch 9/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0881 - accuracy: 0.9788\n",
      "Epoch 10/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0542 - accuracy: 0.9882\n",
      "Epoch 11/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0344 - accuracy: 0.9938\n",
      "Epoch 12/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0233 - accuracy: 0.9960\n",
      "Epoch 13/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0170 - accuracy: 0.9970\n",
      "Epoch 14/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0121 - accuracy: 0.9981\n",
      "Epoch 15/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.9993\n",
      "Epoch 16/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "Epoch 17/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0049 - accuracy: 0.9992\n",
      "Epoch 18/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0052 - accuracy: 0.9988\n",
      "Epoch 19/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9990\n",
      "Epoch 20/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0072 - accuracy: 0.9982\n",
      "Epoch 21/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0170 - accuracy: 0.9954\n",
      "Epoch 22/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0263 - accuracy: 0.9925\n",
      "Epoch 23/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0254 - accuracy: 0.9928\n",
      "Epoch 24/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0154 - accuracy: 0.9953\n",
      "Epoch 25/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0083 - accuracy: 0.9980\n",
      "Epoch 26/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9987\n",
      "Epoch 27/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 0.9992\n",
      "Epoch 28/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 29/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 30/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 31/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 32/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.1255e-04 - accuracy: 0.9999\n",
      "Epoch 33/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 34/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 9.6417e-04 - accuracy: 0.9998\n",
      "Epoch 35/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 9.1189e-04 - accuracy: 0.9998\n",
      "Epoch 36/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.7943e-04 - accuracy: 0.9999\n",
      "Epoch 37/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 2.0099e-04 - accuracy: 1.0000\n",
      "Epoch 38/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.1868e-04 - accuracy: 1.0000\n",
      "Epoch 39/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 8.5557e-05 - accuracy: 1.0000\n",
      "Epoch 40/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.3713e-05 - accuracy: 1.0000\n",
      "Epoch 41/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 6.4689e-05 - accuracy: 1.0000\n",
      "Epoch 42/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.7956e-05 - accuracy: 1.0000\n",
      "Epoch 43/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 5.1916e-05 - accuracy: 1.0000\n",
      "Epoch 44/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.5625e-05 - accuracy: 1.0000\n",
      "Epoch 45/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 4.0827e-05 - accuracy: 1.0000\n",
      "Epoch 46/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 3.6416e-05 - accuracy: 1.0000\n",
      "Epoch 47/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 3.2181e-05 - accuracy: 1.0000\n",
      "Epoch 48/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.8481e-05 - accuracy: 1.0000\n",
      "Epoch 49/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 2.5140e-05 - accuracy: 1.0000\n",
      "Epoch 50/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 2.2792e-05 - accuracy: 1.0000\n",
      "Epoch 51/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.9596e-05 - accuracy: 1.0000\n",
      "Epoch 52/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.7522e-05 - accuracy: 1.0000\n",
      "Epoch 53/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.5642e-05 - accuracy: 1.0000\n",
      "Epoch 54/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.3783e-05 - accuracy: 1.0000\n",
      "Epoch 55/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.2054e-05 - accuracy: 1.0000\n",
      "Epoch 56/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0625e-05 - accuracy: 1.0000\n",
      "Epoch 57/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 9.3777e-06 - accuracy: 1.0000\n",
      "Epoch 58/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 8.3237e-06 - accuracy: 1.0000\n",
      "Epoch 59/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.2299e-06 - accuracy: 1.0000\n",
      "Epoch 60/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.3520e-06 - accuracy: 1.0000\n",
      "Epoch 61/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.6198e-06 - accuracy: 1.0000\n",
      "Epoch 62/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.0598e-06 - accuracy: 1.0000\n",
      "Epoch 63/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
      "Epoch 64/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0415 - accuracy: 0.9893\n",
      "Epoch 65/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0576 - accuracy: 0.9828\n",
      "Epoch 66/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0166 - accuracy: 0.9948\n",
      "Epoch 67/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 0.9988\n",
      "Epoch 68/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 8.3815e-04 - accuracy: 0.9998\n",
      "Epoch 69/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.8688e-04 - accuracy: 0.9999\n",
      "Epoch 70/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.1719e-05 - accuracy: 1.0000\n",
      "Epoch 71/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.7993e-05 - accuracy: 1.0000\n",
      "Epoch 72/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.9813e-05 - accuracy: 1.0000\n",
      "Epoch 73/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.4739e-05 - accuracy: 1.0000\n",
      "Epoch 74/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.0652e-05 - accuracy: 1.0000\n",
      "Epoch 75/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.7343e-05 - accuracy: 1.0000\n",
      "Epoch 76/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.4534e-05 - accuracy: 1.0000\n",
      "Epoch 77/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.2090e-05 - accuracy: 1.0000\n",
      "Epoch 78/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 2.0040e-05 - accuracy: 1.0000\n",
      "Epoch 79/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.8122e-05 - accuracy: 1.0000\n",
      "Epoch 80/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.6417e-05 - accuracy: 1.0000\n",
      "Epoch 81/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.4954e-05 - accuracy: 1.0000\n",
      "Epoch 82/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.3573e-05 - accuracy: 1.0000\n",
      "Epoch 83/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2334e-05 - accuracy: 1.0000\n",
      "Epoch 84/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.1265e-05 - accuracy: 1.0000\n",
      "Epoch 85/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0205e-05 - accuracy: 1.0000\n",
      "Epoch 86/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 9.3407e-06 - accuracy: 1.0000\n",
      "Epoch 87/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 8.5282e-06 - accuracy: 1.0000\n",
      "Epoch 88/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2372e-05 - accuracy: 1.0000\n",
      "Epoch 89/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.1756e-05 - accuracy: 1.0000\n",
      "Epoch 90/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.0129e-06 - accuracy: 1.0000\n",
      "Epoch 91/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.9883e-06 - accuracy: 1.0000\n",
      "Epoch 92/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.5642e-06 - accuracy: 1.0000\n",
      "Epoch 93/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.7029e-06 - accuracy: 1.0000\n",
      "Epoch 94/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 4.3193e-06 - accuracy: 1.0000\n",
      "Epoch 95/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 3.8627e-06 - accuracy: 1.0000\n",
      "Epoch 96/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.4932e-06 - accuracy: 1.0000\n",
      "Epoch 97/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 4.6474e-05 - accuracy: 1.0000\n",
      "Epoch 98/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.1731e-04 - accuracy: 0.9999\n",
      "Epoch 99/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0085 - accuracy: 0.9977\n",
      "Epoch 100/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0172 - accuracy: 0.9959\n",
      "Epoch 101/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9985\n",
      "Epoch 102/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 103/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.8400e-04 - accuracy: 0.9999\n",
      "Epoch 104/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.2900e-04 - accuracy: 0.9998\n",
      "Epoch 105/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 8.9991e-05 - accuracy: 1.0000\n",
      "Epoch 106/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 8.8923e-04 - accuracy: 0.9999\n",
      "Epoch 107/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.4058e-05 - accuracy: 1.0000\n",
      "Epoch 108/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 9.0948e-06 - accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.7413e-06 - accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.6619e-06 - accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.9988e-06 - accuracy: 1.0000\n",
      "Epoch 112/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.4014e-06 - accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.8956e-06 - accuracy: 1.0000\n",
      "Epoch 114/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.5522e-06 - accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 3.1721e-06 - accuracy: 1.0000\n",
      "Epoch 116/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.8559e-06 - accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.6030e-06 - accuracy: 1.0000\n",
      "Epoch 118/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.3160e-06 - accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.1265e-06 - accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.9359e-06 - accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.7605e-06 - accuracy: 1.0000\n",
      "Epoch 122/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.6243e-06 - accuracy: 1.0000\n",
      "Epoch 123/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.4684e-06 - accuracy: 1.0000\n",
      "Epoch 124/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.3255e-06 - accuracy: 1.0000\n",
      "Epoch 125/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2204e-06 - accuracy: 1.0000\n",
      "Epoch 126/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.1312e-06 - accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0036e-06 - accuracy: 1.0000\n",
      "Epoch 128/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 9.1429e-07 - accuracy: 1.0000\n",
      "Epoch 129/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 8.4745e-07 - accuracy: 1.0000\n",
      "Epoch 130/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.6341e-07 - accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.9457e-07 - accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.3268e-07 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.7450e-07 - accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.3606e-07 - accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.9356e-07 - accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.3390e-07 - accuracy: 1.0000\n",
      "Epoch 137/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.9631e-07 - accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.6053e-07 - accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.2755e-07 - accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.9378e-07 - accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.6625e-07 - accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.4536e-07 - accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.1706e-07 - accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.9837e-07 - accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.7940e-07 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.6159e-07 - accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.4651e-07 - accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.3419e-07 - accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.1848e-07 - accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0648e-07 - accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 9.6359e-08 - accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 8.6758e-08 - accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.7860e-08 - accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.0597e-08 - accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.4591e-08 - accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.7240e-08 - accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.1728e-08 - accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.7486e-08 - accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.4508e-08 - accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.7405e-08 - accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.3715e-08 - accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.0469e-08 - accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.7738e-08 - accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.5174e-08 - accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.2501e-08 - accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.0344e-08 - accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.8245e-08 - accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.6901e-08 - accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.5231e-08 - accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.3705e-08 - accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2543e-08 - accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.1374e-08 - accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0292e-08 - accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 9.6817e-09 - accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 8.6358e-09 - accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.8369e-09 - accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.2922e-09 - accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.5731e-09 - accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.2608e-09 - accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.5490e-09 - accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.2512e-09 - accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.9752e-09 - accuracy: 1.0000\n",
      "Epoch 183/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.6702e-09 - accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 4.4232e-09 - accuracy: 1.0000\n",
      "Epoch 185/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.0673e-09 - accuracy: 1.0000\n",
      "Epoch 186/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.9003e-09 - accuracy: 1.0000\n",
      "Epoch 187/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.8277e-09 - accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.7478e-09 - accuracy: 1.0000\n",
      "Epoch 189/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.6170e-09 - accuracy: 1.0000\n",
      "Epoch 190/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.5371e-09 - accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.5299e-09 - accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.3991e-09 - accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.7042e-09 - accuracy: 1.0000\n",
      "Epoch 194/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.5662e-09 - accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.5952e-09 - accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.6824e-09 - accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.7550e-09 - accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.8712e-09 - accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.2271e-09 - accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.9825e-09 - accuracy: 1.0000\n",
      "Epoch 201/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 202/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0155 - accuracy: 0.9956\n",
      "Epoch 203/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0023 - accuracy: 0.9990\n",
      "Epoch 204/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 205/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2228e-04 - accuracy: 0.9999\n",
      "Epoch 206/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.9479e-06 - accuracy: 1.0000\n",
      "Epoch 207/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.1441e-06 - accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.5924e-06 - accuracy: 1.0000\n",
      "Epoch 209/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.3032e-06 - accuracy: 1.0000\n",
      "Epoch 210/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.1068e-06 - accuracy: 1.0000\n",
      "Epoch 211/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 9.5526e-07 - accuracy: 1.0000\n",
      "Epoch 212/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 8.3582e-07 - accuracy: 1.0000\n",
      "Epoch 213/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.3590e-07 - accuracy: 1.0000\n",
      "Epoch 214/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.5349e-07 - accuracy: 1.0000\n",
      "Epoch 215/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.8339e-07 - accuracy: 1.0000\n",
      "Epoch 216/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.2310e-07 - accuracy: 1.0000\n",
      "Epoch 217/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.7075e-07 - accuracy: 1.0000\n",
      "Epoch 218/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.2417e-07 - accuracy: 1.0000\n",
      "Epoch 219/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.8391e-07 - accuracy: 1.0000\n",
      "Epoch 220/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.4740e-07 - accuracy: 1.0000\n",
      "Epoch 221/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.1533e-07 - accuracy: 1.0000\n",
      "Epoch 222/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.8613e-07 - accuracy: 1.0000\n",
      "Epoch 223/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 2.5985e-07 - accuracy: 1.0000\n",
      "Epoch 224/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.3649e-07 - accuracy: 1.0000\n",
      "Epoch 225/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.1554e-07 - accuracy: 1.0000\n",
      "Epoch 226/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.9630e-07 - accuracy: 1.0000\n",
      "Epoch 227/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.7887e-07 - accuracy: 1.0000\n",
      "Epoch 228/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.6265e-07 - accuracy: 1.0000\n",
      "Epoch 229/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.4830e-07 - accuracy: 1.0000\n",
      "Epoch 230/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.3530e-07 - accuracy: 1.0000\n",
      "Epoch 231/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2330e-07 - accuracy: 1.0000\n",
      "Epoch 232/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.1235e-07 - accuracy: 1.0000\n",
      "Epoch 233/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0234e-07 - accuracy: 1.0000\n",
      "Epoch 234/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 9.3279e-08 - accuracy: 1.0000\n",
      "Epoch 235/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 8.5196e-08 - accuracy: 1.0000\n",
      "Epoch 236/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.7635e-08 - accuracy: 1.0000\n",
      "Epoch 237/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.0873e-08 - accuracy: 1.0000\n",
      "Epoch 238/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.4423e-08 - accuracy: 1.0000\n",
      "Epoch 239/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.8722e-08 - accuracy: 1.0000\n",
      "Epoch 240/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.3602e-08 - accuracy: 1.0000\n",
      "Epoch 241/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.8517e-08 - accuracy: 1.0000\n",
      "Epoch 242/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.4457e-08 - accuracy: 1.0000\n",
      "Epoch 243/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.0419e-08 - accuracy: 1.0000\n",
      "Epoch 244/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.6809e-08 - accuracy: 1.0000\n",
      "Epoch 245/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.3468e-08 - accuracy: 1.0000\n",
      "Epoch 246/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.0585e-08 - accuracy: 1.0000\n",
      "Epoch 247/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 2.7883e-08 - accuracy: 1.0000\n",
      "Epoch 248/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.5421e-08 - accuracy: 1.0000\n",
      "Epoch 249/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.3213e-08 - accuracy: 1.0000\n",
      "Epoch 250/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.1128e-08 - accuracy: 1.0000\n",
      "Epoch 251/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.9327e-08 - accuracy: 1.0000\n",
      "Epoch 252/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.7700e-08 - accuracy: 1.0000\n",
      "Epoch 253/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.6204e-08 - accuracy: 1.0000\n",
      "Epoch 254/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.4788e-08 - accuracy: 1.0000\n",
      "Epoch 255/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.3509e-08 - accuracy: 1.0000\n",
      "Epoch 256/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2376e-08 - accuracy: 1.0000\n",
      "Epoch 257/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.1214e-08 - accuracy: 1.0000\n",
      "Epoch 258/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0255e-08 - accuracy: 1.0000\n",
      "Epoch 259/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 9.5074e-09 - accuracy: 1.0000\n",
      "Epoch 260/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 8.6794e-09 - accuracy: 1.0000\n",
      "Epoch 261/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.8950e-09 - accuracy: 1.0000\n",
      "Epoch 262/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.2413e-09 - accuracy: 1.0000\n",
      "Epoch 263/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.6748e-09 - accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.1301e-09 - accuracy: 1.0000\n",
      "Epoch 265/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.5635e-09 - accuracy: 1.0000\n",
      "Epoch 266/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.1205e-09 - accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.5903e-09 - accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.2417e-09 - accuracy: 1.0000\n",
      "Epoch 269/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.0165e-09 - accuracy: 1.0000\n",
      "Epoch 270/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.6606e-09 - accuracy: 1.0000\n",
      "Epoch 271/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.1885e-09 - accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.0650e-09 - accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 2.8108e-09 - accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.6292e-09 - accuracy: 1.0000\n",
      "Epoch 275/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.4840e-09 - accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.2298e-09 - accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.1644e-09 - accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.9538e-09 - accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.7867e-09 - accuracy: 1.0000\n",
      "Epoch 280/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.8158e-09 - accuracy: 1.0000\n",
      "Epoch 281/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.4889e-09 - accuracy: 1.0000\n",
      "Epoch 282/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.5761e-09 - accuracy: 1.0000\n",
      "Epoch 283/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.4090e-09 - accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2783e-09 - accuracy: 1.0000\n",
      "Epoch 285/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.3873e-09 - accuracy: 1.0000\n",
      "Epoch 286/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2493e-09 - accuracy: 1.0000\n",
      "Epoch 287/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.1766e-09 - accuracy: 1.0000\n",
      "Epoch 288/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0749e-09 - accuracy: 1.0000\n",
      "Epoch 289/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.1258e-09 - accuracy: 1.0000\n",
      "Epoch 290/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.1694e-09 - accuracy: 1.0000\n",
      "Epoch 291/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0386e-09 - accuracy: 1.0000\n",
      "Epoch 292/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.1185e-09 - accuracy: 1.0000\n",
      "Epoch 293/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0967e-09 - accuracy: 1.0000\n",
      "Epoch 294/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2057e-09 - accuracy: 1.0000\n",
      "Epoch 295/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2202e-09 - accuracy: 1.0000\n",
      "Epoch 296/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.1403e-09 - accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2783e-09 - accuracy: 1.0000\n",
      "Epoch 298/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2057e-09 - accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2856e-09 - accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.4526e-09 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2956f921a80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련 및 콜백 설정\n",
    "model2.fit([X_train[:, 0], X_train[:, 1], X_train[:, 2], X_train[:, 3], X_train[:, 4]], y_train_categorical, epochs=300, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f6bf9ef-25a1-4062-9bc9-cf5193ded84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 849us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = model2.predict([X_test[:, 0], X_test[:, 1], X_test[:, 2], X_test[:, 3], X_test[:, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4405db1-b567-4c0a-b6cb-fb0b401df3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes2 = np.argmax(y_pred2, axis=1)\n",
    "# 정답과 비교할 때 카테고리화 된 y_test 필요\n",
    "y_test_classes2 = np.argmax(y_test_categorical, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e67c8125-9925-4e8d-a125-281506d82e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([54, 33, 24, ..., 20, 25, 40], dtype=int64),\n",
       " array([54, 33, 24, ..., 51, 25, 40], dtype=int64))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_classes2,y_test_classes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3aedcfca-2d48-4c02-b255-5d4d9ad2bec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.27%\n"
     ]
    }
   ],
   "source": [
    "# 정확도 계산\n",
    "correct = np.sum(y_pred_classes2 == y_test_classes2)\n",
    "accuracy = correct / y_test_classes2.shape[0]\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c793ea37-42db-423c-a5bb-1f09fc5a4f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 77.90%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test_classes2, y_pred_classes2, average='weighted')\n",
    "print(\"F1 Score: {:.2f}%\".format(f1 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d66f56a-8f2c-40e7-90b7-71c1f568e926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "458cdfd6-c885-48c7-8e7a-e82113cb1fa4",
   "metadata": {},
   "source": [
    "# model3 : model1 + lstm + cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53582a51-e018-41a5-a828-582c6084dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Embedding, Dense, concatenate, Flatten, Conv1D, GlobalMaxPooling1D\n",
    "# 출력 통합\n",
    "merged_output = concatenate([embedding1, embedding2, embedding3, embedding4, embedding5], axis=-1)\n",
    "\n",
    "\n",
    "# CNN Layer\n",
    "cnn_output = Conv1D(filters=128, kernel_size=1, activation='relu')(merged_output)  # kernel_size 수정\n",
    "cnn_output = GlobalMaxPooling1D()(cnn_output)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_output = LSTM(128)(merged_output)\n",
    "\n",
    "# Dense Layer\n",
    "dense_input = concatenate([cnn_output, lstm_output], axis=-1)\n",
    "dense_output = Dense(64, activation='relu', name='Dense_output')(dense_input)\n",
    "\n",
    "prediction = Dense(61, activation='softmax', name=\"Prediction_output\")(dense_output)\n",
    "\n",
    "# 모델 생성\n",
    "model3 = Model(inputs=[input1, input2, input3, input4, input5], outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47cab401-73b7-4b05-a99a-a644e2f08b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Subject_Input (InputLayer)     [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Machinery_Input (InputLayer)   [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Assembly_Input (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Part_No.1_Input (InputLayer)   [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " 청구품목_Input (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Subject_Embedding (Embedding)  (None, 1, 8)         13736       ['Subject_Input[0][0]']          \n",
      "                                                                                                  \n",
      " Assembly_Embedding (Embedding)  (None, 1, 8)        1400        ['Machinery_Input[0][0]']        \n",
      "                                                                                                  \n",
      " Resource_Embedding (Embedding)  (None, 1, 8)        13472       ['Assembly_Input[0][0]']         \n",
      "                                                                                                  \n",
      " Method_Embedding (Embedding)   (None, 1, 8)         65024       ['Part_No.1_Input[0][0]']        \n",
      "                                                                                                  \n",
      " Dwg_Embedding (Embedding)      (None, 1, 8)         49040       ['청구품목_Input[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 1, 40)        0           ['Subject_Embedding[0][0]',      \n",
      "                                                                  'Assembly_Embedding[0][0]',     \n",
      "                                                                  'Resource_Embedding[0][0]',     \n",
      "                                                                  'Method_Embedding[0][0]',       \n",
      "                                                                  'Dwg_Embedding[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1, 128)       5248        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 128)         0           ['conv1d[0][0]']                 \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 128)          86528       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256)          0           ['global_max_pooling1d[0][0]',   \n",
      "                                                                  'lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " Dense_output (Dense)           (None, 64)           16448       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " Prediction_output (Dense)      (None, 61)           3965        ['Dense_output[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 254,861\n",
      "Trainable params: 254,861\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "# 모델 컴파일\n",
    "learning_rate = 0.001  # 원하는 학습률 값 설정하기\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "# 모델 컴파일\n",
    "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e990c007-9581-4514-a370-bc4760868f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_categorical = to_categorical(y_train, num_classes=61)\n",
    "y_test_categorical = to_categorical(y_test, num_classes=61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a38d1b2-e40c-4e18-8c0c-6828c2306492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "257/257 [==============================] - 3s 2ms/step - loss: 1.8310 - accuracy: 0.5716\n",
      "Epoch 2/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.1930 - accuracy: 0.9739\n",
      "Epoch 3/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0296 - accuracy: 0.9978\n",
      "Epoch 4/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0096 - accuracy: 0.9995\n",
      "Epoch 5/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9997\n",
      "Epoch 6/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0031 - accuracy: 0.9998\n",
      "Epoch 7/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0020 - accuracy: 0.9999\n",
      "Epoch 8/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9999\n",
      "Epoch 9/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 9.9092e-04 - accuracy: 0.9999\n",
      "Epoch 10/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 7.4322e-04 - accuracy: 0.9999\n",
      "Epoch 11/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 5.4473e-04 - accuracy: 0.9999\n",
      "Epoch 12/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 4.1819e-04 - accuracy: 1.0000\n",
      "Epoch 13/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.2149e-04 - accuracy: 1.0000\n",
      "Epoch 14/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.4786e-04 - accuracy: 1.0000\n",
      "Epoch 15/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.9105e-04 - accuracy: 1.0000\n",
      "Epoch 16/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.5201e-04 - accuracy: 1.0000\n",
      "Epoch 17/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.2352e-04 - accuracy: 1.0000\n",
      "Epoch 18/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0304e-04 - accuracy: 1.0000\n",
      "Epoch 19/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 8.4585e-05 - accuracy: 1.0000\n",
      "Epoch 20/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 7.0393e-05 - accuracy: 1.0000\n",
      "Epoch 21/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 5.9042e-05 - accuracy: 1.0000\n",
      "Epoch 22/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.9011e-05 - accuracy: 1.0000\n",
      "Epoch 23/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.1833e-05 - accuracy: 1.0000\n",
      "Epoch 24/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.7054e-05 - accuracy: 1.0000\n",
      "Epoch 25/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 0.9995\n",
      "Epoch 26/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 27/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0020 - accuracy: 0.9997\n",
      "Epoch 28/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.8657e-04 - accuracy: 0.9999\n",
      "Epoch 29/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 4.8640e-05 - accuracy: 1.0000\n",
      "Epoch 30/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.5729e-05 - accuracy: 1.0000\n",
      "Epoch 31/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.0880e-05 - accuracy: 1.0000\n",
      "Epoch 32/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.7777e-05 - accuracy: 1.0000\n",
      "Epoch 33/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.5426e-05 - accuracy: 1.0000\n",
      "Epoch 34/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.3570e-05 - accuracy: 1.0000\n",
      "Epoch 35/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.1968e-05 - accuracy: 1.0000\n",
      "Epoch 36/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.0626e-05 - accuracy: 1.0000\n",
      "Epoch 37/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 9.3911e-06 - accuracy: 1.0000\n",
      "Epoch 38/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 8.3248e-06 - accuracy: 1.0000\n",
      "Epoch 39/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.3957e-06 - accuracy: 1.0000\n",
      "Epoch 40/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.6239e-06 - accuracy: 1.0000\n",
      "Epoch 41/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.9670e-06 - accuracy: 1.0000\n",
      "Epoch 42/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.2222e-06 - accuracy: 1.0000\n",
      "Epoch 43/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 4.6739e-06 - accuracy: 1.0000\n",
      "Epoch 44/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.2099e-06 - accuracy: 1.0000\n",
      "Epoch 45/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.6981e-06 - accuracy: 1.0000\n",
      "Epoch 46/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.3157e-06 - accuracy: 1.0000\n",
      "Epoch 47/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.9643e-06 - accuracy: 1.0000\n",
      "Epoch 48/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.6148e-06 - accuracy: 1.0000\n",
      "Epoch 49/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.3251e-06 - accuracy: 1.0000\n",
      "Epoch 50/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.1045e-06 - accuracy: 1.0000\n",
      "Epoch 51/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.8407e-06 - accuracy: 1.0000\n",
      "Epoch 52/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.6224e-06 - accuracy: 1.0000\n",
      "Epoch 53/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.4386e-06 - accuracy: 1.0000\n",
      "Epoch 54/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2816e-06 - accuracy: 1.0000\n",
      "Epoch 55/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.1342e-06 - accuracy: 1.0000\n",
      "Epoch 56/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0333e-06 - accuracy: 1.0000\n",
      "Epoch 57/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 8.9074e-07 - accuracy: 1.0000\n",
      "Epoch 58/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 7.9524e-07 - accuracy: 1.0000\n",
      "Epoch 59/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.0094e-07 - accuracy: 1.0000\n",
      "Epoch 60/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.1568e-07 - accuracy: 1.0000\n",
      "Epoch 61/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.4573e-07 - accuracy: 1.0000\n",
      "Epoch 62/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.8330e-07 - accuracy: 1.0000\n",
      "Epoch 63/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.2845e-07 - accuracy: 1.0000\n",
      "Epoch 64/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.7837e-07 - accuracy: 1.0000\n",
      "Epoch 65/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.3475e-07 - accuracy: 1.0000\n",
      "Epoch 66/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.9531e-07 - accuracy: 1.0000\n",
      "Epoch 67/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.6297e-07 - accuracy: 1.0000\n",
      "Epoch 68/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.3274e-07 - accuracy: 1.0000\n",
      "Epoch 69/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.1029e-07 - accuracy: 1.0000\n",
      "Epoch 70/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.8179e-07 - accuracy: 1.0000\n",
      "Epoch 71/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.6035e-07 - accuracy: 1.0000\n",
      "Epoch 72/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.4671e-07 - accuracy: 1.0000\n",
      "Epoch 73/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.3327e-07 - accuracy: 1.0000\n",
      "Epoch 74/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.1137e-07 - accuracy: 1.0000\n",
      "Epoch 75/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 9.8168e-08 - accuracy: 1.0000\n",
      "Epoch 76/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 8.7092e-08 - accuracy: 1.0000\n",
      "Epoch 77/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.6894e-08 - accuracy: 1.0000\n",
      "Epoch 78/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.7779e-08 - accuracy: 1.0000\n",
      "Epoch 79/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.9405e-08 - accuracy: 1.0000\n",
      "Epoch 80/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 5.3841e-08 - accuracy: 1.0000\n",
      "Epoch 81/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.7457e-08 - accuracy: 1.0000\n",
      "Epoch 82/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.1559e-08 - accuracy: 1.0000\n",
      "Epoch 83/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.6729e-08 - accuracy: 1.0000\n",
      "Epoch 84/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.3345e-08 - accuracy: 1.0000\n",
      "Epoch 85/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 2.9459e-08 - accuracy: 1.0000\n",
      "Epoch 86/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.6307e-08 - accuracy: 1.0000\n",
      "Epoch 87/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.4230e-08 - accuracy: 1.0000\n",
      "Epoch 88/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.1470e-08 - accuracy: 1.0000\n",
      "Epoch 89/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.9501e-08 - accuracy: 1.0000\n",
      "Epoch 90/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.7874e-08 - accuracy: 1.0000\n",
      "Epoch 91/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.6778e-08 - accuracy: 1.0000\n",
      "Epoch 92/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.5412e-08 - accuracy: 1.0000\n",
      "Epoch 93/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.4635e-08 - accuracy: 1.0000\n",
      "Epoch 94/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.3909e-08 - accuracy: 1.0000\n",
      "Epoch 95/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.3059e-08 - accuracy: 1.0000\n",
      "Epoch 96/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2907e-08 - accuracy: 1.0000\n",
      "Epoch 97/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.3262e-08 - accuracy: 1.0000\n",
      "Epoch 98/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.2790e-08 - accuracy: 1.0000\n",
      "Epoch 99/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.2994e-08 - accuracy: 1.0000\n",
      "Epoch 100/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.3524e-08 - accuracy: 1.0000\n",
      "Epoch 101/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.4185e-08 - accuracy: 1.0000\n",
      "Epoch 102/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.9785e-08 - accuracy: 1.0000\n",
      "Epoch 103/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9982\n",
      "Epoch 104/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0071 - accuracy: 0.9980\n",
      "Epoch 105/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 106/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 8.0625e-04 - accuracy: 0.9998\n",
      "Epoch 107/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 5.5250e-05 - accuracy: 0.9999\n",
      "Epoch 108/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.4456e-06 - accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.9681e-06 - accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.6655e-06 - accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.4144e-06 - accuracy: 1.0000\n",
      "Epoch 112/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2333e-06 - accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.0805e-06 - accuracy: 1.0000\n",
      "Epoch 114/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 9.5549e-07 - accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 8.5304e-07 - accuracy: 1.0000\n",
      "Epoch 116/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 7.6609e-07 - accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 6.7893e-07 - accuracy: 1.0000\n",
      "Epoch 118/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.1617e-07 - accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.5492e-07 - accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.0021e-07 - accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 4.5213e-07 - accuracy: 1.0000\n",
      "Epoch 122/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 4.1013e-07 - accuracy: 1.0000\n",
      "Epoch 123/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 3.6692e-07 - accuracy: 1.0000\n",
      "Epoch 124/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.3812e-07 - accuracy: 1.0000\n",
      "Epoch 125/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.0799e-07 - accuracy: 1.0000\n",
      "Epoch 126/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.8071e-07 - accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.5575e-07 - accuracy: 1.0000\n",
      "Epoch 128/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.3165e-07 - accuracy: 1.0000\n",
      "Epoch 129/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.1223e-07 - accuracy: 1.0000\n",
      "Epoch 130/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.9411e-07 - accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.7706e-07 - accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.6274e-07 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.4834e-07 - accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.3478e-07 - accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2338e-07 - accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.1282e-07 - accuracy: 1.0000\n",
      "Epoch 137/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0260e-07 - accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 9.3773e-08 - accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 8.6227e-08 - accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.8739e-08 - accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 7.1868e-08 - accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.5803e-08 - accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 6.0530e-08 - accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.4931e-08 - accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.0529e-08 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.6150e-08 - accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 4.2162e-08 - accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.8625e-08 - accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 3.5415e-08 - accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.2074e-08 - accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.9401e-08 - accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.6677e-08 - accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.4324e-08 - accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.2043e-08 - accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.9973e-08 - accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.8020e-08 - accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.6356e-08 - accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.4831e-08 - accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.3371e-08 - accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2013e-08 - accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0749e-08 - accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 9.7035e-09 - accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 8.7085e-09 - accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.7715e-09 - accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 7.1687e-09 - accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.2535e-09 - accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.5781e-09 - accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.0987e-09 - accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.5249e-09 - accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.0165e-09 - accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.6098e-09 - accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 3.2393e-09 - accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.9052e-09 - accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.6075e-09 - accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.3387e-09 - accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.2080e-09 - accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.9320e-09 - accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.8230e-09 - accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.6197e-09 - accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.4381e-09 - accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.3001e-09 - accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0895e-09 - accuracy: 1.0000\n",
      "Epoch 183/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0677e-09 - accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 9.6599e-10 - accuracy: 1.0000\n",
      "Epoch 185/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 9.5873e-10 - accuracy: 1.0000\n",
      "Epoch 186/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 8.4978e-10 - accuracy: 1.0000\n",
      "Epoch 187/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.5536e-10 - accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 7.6263e-10 - accuracy: 1.0000\n",
      "Epoch 189/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 6.6821e-10 - accuracy: 1.0000\n",
      "Epoch 190/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 7.1178e-10 - accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.2463e-10 - accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 5.8831e-10 - accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.6094e-10 - accuracy: 1.0000\n",
      "Epoch 194/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 6.2463e-10 - accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 5.9557e-10 - accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 6.0284e-10 - accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 6.6821e-10 - accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.3915e-10 - accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.7547e-10 - accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 9.0062e-10 - accuracy: 1.0000\n",
      "Epoch 201/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 8.9336e-10 - accuracy: 1.0000\n",
      "Epoch 202/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 8.4252e-10 - accuracy: 1.0000\n",
      "Epoch 203/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 9.4420e-10 - accuracy: 1.0000\n",
      "Epoch 204/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.3001e-09 - accuracy: 1.0000\n",
      "Epoch 205/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.6124e-09 - accuracy: 1.0000\n",
      "Epoch 206/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 2.1354e-09 - accuracy: 1.0000\n",
      "Epoch 207/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.3242e-09 - accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.2806e-09 - accuracy: 1.0000\n",
      "Epoch 209/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.5130e-09 - accuracy: 1.0000\n",
      "Epoch 210/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.9779e-09 - accuracy: 1.0000\n",
      "Epoch 211/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.1037e-09 - accuracy: 1.0000\n",
      "Epoch 212/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0021 - accuracy: 0.9997\n",
      "Epoch 213/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 0.0086 - accuracy: 0.9981\n",
      "Epoch 214/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 215/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 8.3774e-04 - accuracy: 0.9999\n",
      "Epoch 216/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.2615e-06 - accuracy: 1.0000\n",
      "Epoch 217/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.3902e-07 - accuracy: 1.0000\n",
      "Epoch 218/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.4518e-07 - accuracy: 1.0000\n",
      "Epoch 219/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.2879e-07 - accuracy: 1.0000\n",
      "Epoch 220/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.4910e-07 - accuracy: 1.0000\n",
      "Epoch 221/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.9023e-07 - accuracy: 1.0000\n",
      "Epoch 222/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.4541e-07 - accuracy: 1.0000\n",
      "Epoch 223/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.1133e-07 - accuracy: 1.0000\n",
      "Epoch 224/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.7516e-07 - accuracy: 1.0000\n",
      "Epoch 225/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.5356e-07 - accuracy: 1.0000\n",
      "Epoch 226/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.3527e-07 - accuracy: 1.0000\n",
      "Epoch 227/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.1962e-07 - accuracy: 1.0000\n",
      "Epoch 228/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.0632e-07 - accuracy: 1.0000\n",
      "Epoch 229/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 9.4601e-08 - accuracy: 1.0000\n",
      "Epoch 230/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 8.4406e-08 - accuracy: 1.0000\n",
      "Epoch 231/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 7.5561e-08 - accuracy: 1.0000\n",
      "Epoch 232/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.7783e-08 - accuracy: 1.0000\n",
      "Epoch 233/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.0942e-08 - accuracy: 1.0000\n",
      "Epoch 234/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.4950e-08 - accuracy: 1.0000\n",
      "Epoch 235/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.9402e-08 - accuracy: 1.0000\n",
      "Epoch 236/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 4.4514e-08 - accuracy: 1.0000\n",
      "Epoch 237/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.0149e-08 - accuracy: 1.0000\n",
      "Epoch 238/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.6191e-08 - accuracy: 1.0000\n",
      "Epoch 239/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.2749e-08 - accuracy: 1.0000\n",
      "Epoch 240/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 2.9706e-08 - accuracy: 1.0000\n",
      "Epoch 241/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.6938e-08 - accuracy: 1.0000\n",
      "Epoch 242/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.4295e-08 - accuracy: 1.0000\n",
      "Epoch 243/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.2058e-08 - accuracy: 1.0000\n",
      "Epoch 244/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.0039e-08 - accuracy: 1.0000\n",
      "Epoch 245/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.8150e-08 - accuracy: 1.0000\n",
      "Epoch 246/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.6465e-08 - accuracy: 1.0000\n",
      "Epoch 247/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.4969e-08 - accuracy: 1.0000\n",
      "Epoch 248/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.3640e-08 - accuracy: 1.0000\n",
      "Epoch 249/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.2485e-08 - accuracy: 1.0000\n",
      "Epoch 250/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.1381e-08 - accuracy: 1.0000\n",
      "Epoch 251/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0314e-08 - accuracy: 1.0000\n",
      "Epoch 252/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 9.3984e-09 - accuracy: 1.0000\n",
      "Epoch 253/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 8.6358e-09 - accuracy: 1.0000\n",
      "Epoch 254/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 7.8223e-09 - accuracy: 1.0000\n",
      "Epoch 255/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 7.1759e-09 - accuracy: 1.0000\n",
      "Epoch 256/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 6.5949e-09 - accuracy: 1.0000\n",
      "Epoch 257/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 5.9485e-09 - accuracy: 1.0000\n",
      "Epoch 258/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 5.4473e-09 - accuracy: 1.0000\n",
      "Epoch 259/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 4.9825e-09 - accuracy: 1.0000\n",
      "Epoch 260/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 4.6266e-09 - accuracy: 1.0000\n",
      "Epoch 261/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.2416e-09 - accuracy: 1.0000\n",
      "Epoch 262/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 3.8277e-09 - accuracy: 1.0000\n",
      "Epoch 263/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 3.5371e-09 - accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 3.2393e-09 - accuracy: 1.0000\n",
      "Epoch 265/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 3.0287e-09 - accuracy: 1.0000\n",
      "Epoch 266/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 2.7309e-09 - accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.5130e-09 - accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 2.2370e-09 - accuracy: 1.0000\n",
      "Epoch 269/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 2.0482e-09 - accuracy: 1.0000\n",
      "Epoch 270/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.8448e-09 - accuracy: 1.0000\n",
      "Epoch 271/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.6996e-09 - accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.5325e-09 - accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.3655e-09 - accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.2347e-09 - accuracy: 1.0000\n",
      "Epoch 275/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0967e-09 - accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.0531e-09 - accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 9.2968e-10 - accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 8.1347e-10 - accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 7.4084e-10 - accuracy: 1.0000\n",
      "Epoch 280/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 6.8273e-10 - accuracy: 1.0000\n",
      "Epoch 281/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.9557e-10 - accuracy: 1.0000\n",
      "Epoch 282/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 5.3747e-10 - accuracy: 1.0000\n",
      "Epoch 283/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 4.9389e-10 - accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 4.7936e-10 - accuracy: 1.0000\n",
      "Epoch 285/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.8494e-10 - accuracy: 1.0000\n",
      "Epoch 286/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 3.8494e-10 - accuracy: 1.0000\n",
      "Epoch 287/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.4137e-10 - accuracy: 1.0000\n",
      "Epoch 288/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 3.4137e-10 - accuracy: 1.0000\n",
      "Epoch 289/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.6147e-10 - accuracy: 1.0000\n",
      "Epoch 290/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.7600e-10 - accuracy: 1.0000\n",
      "Epoch 291/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.2516e-10 - accuracy: 1.0000\n",
      "Epoch 292/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.4695e-10 - accuracy: 1.0000\n",
      "Epoch 293/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 2.1789e-10 - accuracy: 1.0000\n",
      "Epoch 294/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 2.0337e-10 - accuracy: 1.0000\n",
      "Epoch 295/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.8884e-10 - accuracy: 1.0000\n",
      "Epoch 296/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.1621e-10 - accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.4526e-10 - accuracy: 1.0000\n",
      "Epoch 298/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2347e-10 - accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 1.2347e-10 - accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 1.3800e-10 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2957563fc10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련 및 콜백 설정\n",
    "model3.fit([X_train[:, 0], X_train[:, 1], X_train[:, 2], X_train[:, 3], X_train[:, 4]], y_train_categorical, epochs=300, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a68652dc-0a57-40bc-9a12-a20d73427f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 1s 841us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred3 = model3.predict([X_test[:, 0], X_test[:, 1], X_test[:, 2], X_test[:, 3], X_test[:, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac39c10c-afbb-42ef-aa56-21d8954d689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes3 = np.argmax(y_pred3, axis=1)\n",
    "# 정답과 비교할 때 카테고리화 된 y_test 필요\n",
    "y_test_classes3 = np.argmax(y_test_categorical, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aab292c0-4823-4c13-80a5-22d6b6f05a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([54, 33, 24, ..., 18, 25, 40], dtype=int64),\n",
       " array([54, 33, 24, ..., 51, 25, 40], dtype=int64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_classes3,y_test_classes3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56f5f6db-3c86-469e-8d63-7ab977787023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.00%\n"
     ]
    }
   ],
   "source": [
    "# 정확도 계산\n",
    "correct = np.sum(y_pred_classes3 == y_test_classes3)\n",
    "accuracy = correct / y_test_classes3.shape[0]\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "983e46b5-cd7c-4288-9df6-212a59946625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 80.54%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test_classes3, y_pred_classes3, average='weighted')\n",
    "print(\"F1 Score: {:.2f}%\".format(f1 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082d581a-ed21-4f15-9ca4-785bd347a50a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a70a83b-1cd8-4c5e-9b6f-321af0c3a0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74f7d1-4ef5-4521-b413-a769bc64d071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d355d0e-9339-4082-a142-1d3f3c6b12fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92eb902-d787-4f39-a625-e2e75c93a4dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e93264a-915a-4357-b665-b79198601def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de8d8d-a741-4634-b585-f5765c12a761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a82788f-108e-4777-b321-c862ed8084e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c886dd-5671-4294-864a-5bec8b733d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8609499-cb2e-4370-8234-c118ff770f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b8aa77-cf59-4757-8016-c437a68d2c04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
