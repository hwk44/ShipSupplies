{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "261a7657-6dcc-4c74-846b-7753ca0445d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4859b907-8e49-4ce1-8d99-fded5eeccd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca2a05c4-57cd-4915-ab36-49aa6b0c6d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34205099-9c8f-4da3-8d26-468721d091db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # GPU 디바이스 목록 가져오기\n",
    "# gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# if len(gpu_devices) > 0:\n",
    "#     print(\"사용 가능한 GPU가 있습니다.\")\n",
    "#     for device in gpu_devices:\n",
    "#         print(\"GPU 디바이스 이름:\", device.name)\n",
    "# else:\n",
    "#     print(\"사용 가능한 GPU가 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fac9baf-fc45-4766-82be-c6d50dfd830e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install bert-for-tf2\n",
    "# !pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8033901a-87dc-42b1-aaf1-2cda85d9d3d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a242748-4045-47c6-8c1c-c61acba156f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/raw_postpro.csv') # 오류가나면 추가해주세요 .encoding = 'cp949'\n",
    "# 컬럼 삭제\n",
    "df = data.drop(['청구서번호','No.',  '선박입고','완료 여부','리드타임_음수제거','청구량','견적','견적수량','견적화폐','견적단가','발주번호','발주','발주수량','발주금액','미입고 기간','리드타임','창고입고','창고입고수량','입고창고','창고출고','창고출고수량','출고선박','출고운반선','선박입고','선박입고수량','완료 여부'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e7e51b2-e8d8-48c9-b1a7-0fa03ab9e002",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20517 entries, 0 to 20516\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Subject      20517 non-null  object\n",
      " 1   Machinery    20517 non-null  object\n",
      " 2   Assembly     20517 non-null  object\n",
      " 3   청구품목         20517 non-null  object\n",
      " 4   Part No.1    20517 non-null  object\n",
      " 5   Part No.2    20517 non-null  object\n",
      " 6   key1         20517 non-null  object\n",
      " 7   key2         20517 non-null  object\n",
      " 8   발주처          20517 non-null  object\n",
      " 9   D/T          20517 non-null  object\n",
      " 10  Control No.  20517 non-null  object\n",
      " 11  leadtime     20517 non-null  int64 \n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0ac12f6-2aec-4362-b507-d8db659ddb7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[['청구품목','발주처','Machinery', 'Assembly' , \"key1\",'key2']]\n",
    "# 'Machinery', 'Assembly', '청구품목', 'Part No.1', 'Part No.2', 'key1', '발주처'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfa338bd-3298-430c-9534-1f8ddc5a391f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoders = {}  # 각 열에 대한 LabelEncoder를 저장하기 위한 딕셔너리\n",
    "columns_to_encode = ['key2']  # 인코딩을 수행할 열의 이름 리스트\n",
    "\n",
    "for column in columns_to_encode:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df[column])\n",
    "    label_encoders[column] = le # 딕셔너리에 저장\n",
    "    df[column+\"_encoded\"] = le.transform(df[column]) # 새로운 encoding 된 컬럼 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd8e6c31-6c1d-46f0-ad58-7ab1ab285a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(['key2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1d21278-dd5e-4229-9b49-159058e996bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20517 entries, 0 to 20516\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   청구품목          20517 non-null  object\n",
      " 1   발주처           20517 non-null  object\n",
      " 2   Machinery     20517 non-null  object\n",
      " 3   Assembly      20517 non-null  object\n",
      " 4   key1          20517 non-null  object\n",
      " 5   key2_encoded  20517 non-null  int32 \n",
      "dtypes: int32(1), object(5)\n",
      "memory usage: 881.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1644800d-98cf-459d-9811-a594db7e7bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# text = df[[ '청구품목', '발주처','Machinery', 'Assembly' , \"key1\"]].apply(lambda row: ' '.join(row), axis=1)\n",
    "df_text = df[['청구품목', '발주처', 'Machinery', 'Assembly', 'key1']].apply(lambda row: ' '.join(row), axis=1).to_frame(name='text')\n",
    "df_text['key2'] = df['key2_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed53b922-d2f1-473d-b234-b725c024dd66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>key2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEAL-O-RING-STOR HAEIN Coporation_Cheonan NO.1...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OIL COOLER &amp; LINES HAEIN Coporation_Cheonan NO...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WASHER HAEIN Coporation_Cheonan NO.2 GENERATOR...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOLT-HIGH TEMP HAEIN Coporation_Cheonan NO.1 G...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEAL HAEIN Coporation_Cheonan NO.1 GENERATOR E...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CORE CHARGES FOR CYLINDER PACK AS HAEIN Copora...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PUMP GP-F TFR-REMAN HAEIN Coporation_Cheonan N...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.1...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.3...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.3...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.1...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.1...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.3...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IMPELLER (주)정원펌프 NO.1 CONDENSER PUMP PUMP PARTS 3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SELF-ALIGNING ROLLER BEARING 대동베아링상사 BOW THRUS...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TAPERED ROLLER BEARING 대동베아링상사 BOW THRUSTER OV...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SELF-ALIGNING ROLLER BEARING 대동베아링상사 BOW THRUS...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TAPERED ROLLER BEARING 대동베아링상사 BOW THRUSTER OV...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EXHUAST GAS TEMP. INDICATOR, P5 PIRIOU NAVAL S...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EXHAUST GAS TEMPERATURE INDICATOR 0 TO 700℃ PI...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  key2\n",
       "0   SEAL-O-RING-STOR HAEIN Coporation_Cheonan NO.1...    18\n",
       "1   OIL COOLER & LINES HAEIN Coporation_Cheonan NO...    18\n",
       "2   WASHER HAEIN Coporation_Cheonan NO.2 GENERATOR...    18\n",
       "3   BOLT-HIGH TEMP HAEIN Coporation_Cheonan NO.1 G...    18\n",
       "4   SEAL HAEIN Coporation_Cheonan NO.1 GENERATOR E...    18\n",
       "5   CORE CHARGES FOR CYLINDER PACK AS HAEIN Copora...    18\n",
       "6   PUMP GP-F TFR-REMAN HAEIN Coporation_Cheonan N...    18\n",
       "7   GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.1...    18\n",
       "8   GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.3...    18\n",
       "9   GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.3...    18\n",
       "10  GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.1...    18\n",
       "11  GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.1...    18\n",
       "12  GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.3...    18\n",
       "13  IMPELLER (주)정원펌프 NO.1 CONDENSER PUMP PUMP PARTS 3    45\n",
       "14  SELF-ALIGNING ROLLER BEARING 대동베아링상사 BOW THRUS...     4\n",
       "15  TAPERED ROLLER BEARING 대동베아링상사 BOW THRUSTER OV...     4\n",
       "16  SELF-ALIGNING ROLLER BEARING 대동베아링상사 BOW THRUS...     4\n",
       "17  TAPERED ROLLER BEARING 대동베아링상사 BOW THRUSTER OV...    25\n",
       "18  EXHUAST GAS TEMP. INDICATOR, P5 PIRIOU NAVAL S...    25\n",
       "19  EXHAUST GAS TEMPERATURE INDICATOR 0 TO 700℃ PI...    25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a694a2a-3cff-47b1-8c05-d30d50cb99be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text' 'key2']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def preprocess_text(sen):\n",
    "    sentence = remove_tags(sen)\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    return sentence\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "en_text = []\n",
    "sentences = list(df_text['text'])\n",
    "for sen in sentences:\n",
    "    en_text.append(preprocess_text(sen))\n",
    "\n",
    "print(df_text.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bd40d5c-4f5e-4ebf-a48f-e930b433bc33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# en_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d992cd3-dc1e-40d6-a7ab-2abb16ab4d89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df_text.key2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d1d5e47-cada-43bd-acae-6d5cb974dfcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 45,  4,  4,  4,\n",
       "       25, 25, 25])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18cd8304-3fcd-49fa-bb0b-b1312458a1f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4692f2b4-1194-4d3b-8b26-d199db459753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -y tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16bffe19-c415-4d40-a80e-404697702823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip3 install -U \"tensorflow==2.11.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fd4b60f-090a-4376-8c75-1fb94fda3dcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "D:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\tensorflow\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b46cdc6-674f-4b09-af2d-273133e5c2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c3628e-ac27-4afd-a5df-8b7a453e9b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7ab9103-fa6c-44d8-b7dc-172752e7bf1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n",
    "tokenized_text = [tokenize_text(en) for en in en_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ce5a187-7ba8-4da4-abc8-a088c2b5d6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# en_text[0],tokenized_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "577c517f-ad92-48ea-a83d-4ea1a43f2c44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews_with_len = [[text, y[i], len(text)] # 토큰화된 text, key값, text 길이\n",
    "                 for i, text in enumerate(tokenized_text)]\n",
    "# reviews_with_len[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8830b0b6-ed95-4c00-be05-e53c09251cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[23365, 3796, 3796, 23365, 3796], 7, 5],\n",
       " [[16054, 5658, 4049, 3194, 20965, 14027], 8, 6],\n",
       " [[21605, 5658, 4049, 3194, 20965, 13103], 2, 6],\n",
       " [[10764, 5658, 4049, 3194, 7956, 2132], 57, 6],\n",
       " [[9093, 7744, 9347, 29329, 8622, 2112], 48, 6],\n",
       " [[5747, 5658, 4049, 3194, 7956, 3796], 10, 6],\n",
       " [[11220, 7682, 2373, 3796, 2373, 3796], 4, 6],\n",
       " [[7744, 5658, 4049, 3194, 6718, 3847], 24, 6],\n",
       " [[3500, 5658, 4049, 3194, 7956, 2132], 50, 6],\n",
       " [[5009, 5658, 4049, 3194, 7956, 2132], 24, 6],\n",
       " [[17490, 5658, 4049, 3194, 7956, 2132], 39, 6],\n",
       " [[17490, 5658, 4049, 3194, 20965, 13103], 39, 6],\n",
       " [[10764, 5658, 4049, 3194, 7956, 2132], 57, 6],\n",
       " [[10353, 5658, 4049, 3194, 7956, 2132], 19, 6],\n",
       " [[16054, 5658, 4049, 3194, 20965, 14027], 8, 6],\n",
       " [[5009, 5658, 4049, 3194, 7956, 2132], 57, 6],\n",
       " [[7744, 5658, 4049, 3194, 1042, 10216], 24, 6],\n",
       " [[10053, 5658, 4049, 3194, 7956, 3796], 8, 6],\n",
       " [[13354, 5658, 4049, 3194, 20965, 13617], 0, 6],\n",
       " [[5009, 5658, 4049, 3194, 7956, 2132], 57, 6],\n",
       " [[7744, 5658, 4049, 3194, 1055, 10216], 24, 6],\n",
       " [[3500, 10764, 5658, 4049, 3194, 10764], 50, 6],\n",
       " [[5747, 5658, 4049, 3194, 7956, 3796], 10, 6],\n",
       " [[7744, 5658, 4049, 3194, 6718, 3847], 24, 6],\n",
       " [[11307, 3461, 5658, 4049, 3194, 20965, 14027], 23, 7],\n",
       " [[9378, 2121, 5658, 4049, 3194, 20965, 13103], 58, 7],\n",
       " [[16054, 16215, 8879, 2373, 3796, 2691, 3033], 8, 7],\n",
       " [[27000, 16215, 8879, 1044, 25688, 2291, 10122], 23, 7],\n",
       " [[17490, 16215, 8879, 2373, 3796, 2691, 3033], 39, 7],\n",
       " [[16021, 20350, 5658, 4049, 3194, 7956, 2132], 44, 7],\n",
       " [[17490, 16215, 8879, 8722, 3796, 8722, 3796], 39, 7],\n",
       " [[3500, 10764, 5110, 5658, 4049, 3194, 10764], 50, 7],\n",
       " [[3500, 5658, 4049, 3194, 20965, 7956, 2132], 50, 7],\n",
       " [[17727, 24038, 5658, 4049, 3194, 1042, 10216], 45, 7],\n",
       " [[24799, 3796, 2364, 8797, 3313, 3796, 3796], 7, 7],\n",
       " [[9378, 2121, 5658, 4049, 3194, 20965, 13103], 58, 7],\n",
       " [[16054, 16215, 8879, 2373, 3796, 2691, 3033], 8, 7],\n",
       " [[27000, 16215, 8879, 1044, 25688, 2291, 10122], 23, 7],\n",
       " [[1058, 5583, 5658, 4049, 3194, 7633, 5997], 5, 7],\n",
       " [[9378, 2121, 5658, 4049, 3194, 7956, 2132], 24, 7],\n",
       " [[10764, 16215, 8879, 10122, 10122, 4632, 2100], 57, 7],\n",
       " [[7682, 16215, 8879, 8722, 2663, 2818, 13428], 4, 7],\n",
       " [[2491, 16215, 8879, 10122, 10122, 4632, 2100], 17, 7],\n",
       " [[10053, 5658, 4049, 3194, 20965, 4762, 8667], 8, 7],\n",
       " [[11477, 27413, 5658, 4049, 3194, 7633, 5997], 27, 7],\n",
       " [[3482, 16215, 8879, 10122, 10122, 4632, 2100], 17, 7],\n",
       " [[7744, 5658, 4049, 3194, 4875, 22920, 3847], 24, 7],\n",
       " [[16733, 2053, 25416, 29329, 8827, 29329, 3033], 43, 7],\n",
       " [[23365, 3796, 2007, 8103, 3796, 23365, 3796], 7, 7],\n",
       " [[27000, 16215, 8879, 1044, 25688, 2291, 10122], 23, 7]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 섞고 key2 기준으로 정렬\n",
    "import random\n",
    "random.shuffle(reviews_with_len)\n",
    "reviews_with_len.sort(key=lambda x: x[2])\n",
    "reviews_with_len[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07bb61b4-d2b0-49f6-a15b-f7405a7f503d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 7), dtype=int32, numpy=\n",
       " array([[23365,  3796,  3796, 23365,  3796,     0,     0],\n",
       "        [16054,  5658,  4049,  3194, 20965, 14027,     0],\n",
       "        [21605,  5658,  4049,  3194, 20965, 13103,     0],\n",
       "        [10764,  5658,  4049,  3194,  7956,  2132,     0],\n",
       "        [ 9093,  7744,  9347, 29329,  8622,  2112,     0],\n",
       "        [ 5747,  5658,  4049,  3194,  7956,  3796,     0],\n",
       "        [11220,  7682,  2373,  3796,  2373,  3796,     0],\n",
       "        [ 7744,  5658,  4049,  3194,  6718,  3847,     0],\n",
       "        [ 3500,  5658,  4049,  3194,  7956,  2132,     0],\n",
       "        [ 5009,  5658,  4049,  3194,  7956,  2132,     0],\n",
       "        [17490,  5658,  4049,  3194,  7956,  2132,     0],\n",
       "        [17490,  5658,  4049,  3194, 20965, 13103,     0],\n",
       "        [10764,  5658,  4049,  3194,  7956,  2132,     0],\n",
       "        [10353,  5658,  4049,  3194,  7956,  2132,     0],\n",
       "        [16054,  5658,  4049,  3194, 20965, 14027,     0],\n",
       "        [ 5009,  5658,  4049,  3194,  7956,  2132,     0],\n",
       "        [ 7744,  5658,  4049,  3194,  1042, 10216,     0],\n",
       "        [10053,  5658,  4049,  3194,  7956,  3796,     0],\n",
       "        [13354,  5658,  4049,  3194, 20965, 13617,     0],\n",
       "        [ 5009,  5658,  4049,  3194,  7956,  2132,     0],\n",
       "        [ 7744,  5658,  4049,  3194,  1055, 10216,     0],\n",
       "        [ 3500, 10764,  5658,  4049,  3194, 10764,     0],\n",
       "        [ 5747,  5658,  4049,  3194,  7956,  3796,     0],\n",
       "        [ 7744,  5658,  4049,  3194,  6718,  3847,     0],\n",
       "        [11307,  3461,  5658,  4049,  3194, 20965, 14027],\n",
       "        [ 9378,  2121,  5658,  4049,  3194, 20965, 13103],\n",
       "        [16054, 16215,  8879,  2373,  3796,  2691,  3033],\n",
       "        [27000, 16215,  8879,  1044, 25688,  2291, 10122],\n",
       "        [17490, 16215,  8879,  2373,  3796,  2691,  3033],\n",
       "        [16021, 20350,  5658,  4049,  3194,  7956,  2132],\n",
       "        [17490, 16215,  8879,  8722,  3796,  8722,  3796],\n",
       "        [ 3500, 10764,  5110,  5658,  4049,  3194, 10764]])>,\n",
       " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       " array([ 7,  8,  2, 57, 48, 10,  4, 24, 50, 24, 39, 39, 57, 19,  8, 57, 24,\n",
       "         8,  0, 57, 24, 50, 10, 24, 23, 58,  8, 23, 39, 44, 39, 50])>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sorted_text_labels = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len]\n",
    "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_text_labels, output_types=(tf.int32, tf.int32))\n",
    "BATCH_SIZE = 32\n",
    "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))\n",
    "next(iter(batched_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cb20ff8-dc7e-4324-a2a0-5789ebead578",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "TOTAL_BATCHES = math.ceil(len(sorted_text_labels) / BATCH_SIZE)\n",
    "TEST_BATCHES = TOTAL_BATCHES // 10\n",
    "batched_dataset.shuffle(TOTAL_BATCHES)\n",
    "test_data = batched_dataset.take(TEST_BATCHES)\n",
    "train_data = batched_dataset.skip(TEST_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d515ac2-7535-4bb1-8061-648cacec3af2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=(None, None), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "578510c7-5aa2-41ca-ac7c-8e929ee1211a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for inputs, targets in train_data:\n",
    "#     print(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1d7db5f-810f-4eb2-866e-7061524b6ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(642, 64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_BATCHES, TEST_BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22930b57-8bec-4be1-ac33-56b746519db2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TEXT_MODEL(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dimensions=128,\n",
    "                 cnn_filters=50,\n",
    "                 dnn_units=512,\n",
    "                 model_output_classes=2,\n",
    "                 dropout_rate=0.1,\n",
    "                 training=False,\n",
    "                 name=\"text_model\"):\n",
    "        super(TEXT_MODEL, self).__init__(name=name)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocabulary_size,\n",
    "                                          embedding_dimensions)\n",
    "        self.cnn_layer1 = tf.keras.layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=2,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer2 = tf.keras.layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=3,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer3 = tf.keras.layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=4,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.lstm = tf.keras.layers.LSTM(128)\n",
    "        \n",
    "        self.pool = tf.keras.layers.GlobalMaxPool1D()\n",
    "        self.dense_1 = tf.keras.layers.Dense(units=dnn_units, activation=\"relu\")\n",
    "        self.dropout = tf.keras.layers.Dropout(rate=dropout_rate)\n",
    "        if model_output_classes == 2:\n",
    "            self.last_dense = tf.keras.layers.Dense(units=1,\n",
    "                                           activation=\"sigmoid\")\n",
    "        else:\n",
    "            self.last_dense = tf.keras.layers.Dense(units=model_output_classes,\n",
    "                                           activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        l = self.embedding(inputs)\n",
    "        l_1 = self.cnn_layer1(l) \n",
    "        l_1 = self.pool(l_1) \n",
    "        l_2 = self.cnn_layer2(l) \n",
    "        l_2 = self.pool(l_2)\n",
    "        l_3 = self.cnn_layer3(l)\n",
    "        l_3 = self.pool(l_3)\n",
    "        \n",
    "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1) \n",
    "        concatenated = self.dense_1(concatenated)\n",
    "        concatenated = self.dropout(concatenated, training)\n",
    "                # LSTM 레이어에 입력을 3D 형상으로 변환하여 전달\n",
    "        lstm_output = self.lstm(tf.expand_dims(concatenated, axis=1))\n",
    "        \n",
    "        model_output = self.last_dense(concatenated)\n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b2b71ae-53a6-44ea-aa06-6c4b9e1e9a43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_LENGTH = len(tokenizer.vocab)\n",
    "EMB_DIM = 100 #200\n",
    "CNN_FILTERS = 50 #100\n",
    "DNN_UNITS = 128 #256\n",
    "OUTPUT_CLASSES = 61\n",
    "DROPOUT_RATE = 0.1 # 0.2\n",
    "NB_EPOCHS = 60\n",
    "VOCAB_LENGTH\n",
    "# 100 50 128 61 0.1 10 =>0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca899cba-5549-4283-9123-2f252e251d29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
    "                        embedding_dimensions=EMB_DIM,\n",
    "                        cnn_filters=CNN_FILTERS,\n",
    "                        dnn_units=DNN_UNITS,\n",
    "                        model_output_classes=OUTPUT_CLASSES,\n",
    "                        dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35450859-2c35-42ec-b5f0-08a21283ccf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['text_model/lstm_1/lstm_cell_1/kernel:0', 'text_model/lstm_1/lstm_cell_1/recurrent_kernel:0', 'text_model/lstm_1/lstm_cell_1/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['text_model/lstm_1/lstm_cell_1/kernel:0', 'text_model/lstm_1/lstm_cell_1/recurrent_kernel:0', 'text_model/lstm_1/lstm_cell_1/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['text_model/lstm_1/lstm_cell_1/kernel:0', 'text_model/lstm_1/lstm_cell_1/recurrent_kernel:0', 'text_model/lstm_1/lstm_cell_1/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['text_model/lstm_1/lstm_cell_1/kernel:0', 'text_model/lstm_1/lstm_cell_1/recurrent_kernel:0', 'text_model/lstm_1/lstm_cell_1/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 5s 7ms/step - loss: 2.2166 - sparse_categorical_accuracy: 0.4914\n",
      "Epoch 2/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 1.2136 - sparse_categorical_accuracy: 0.7200\n",
      "Epoch 3/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.9352 - sparse_categorical_accuracy: 0.7755\n",
      "Epoch 4/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.8071 - sparse_categorical_accuracy: 0.8028\n",
      "Epoch 5/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.7348 - sparse_categorical_accuracy: 0.8172\n",
      "Epoch 6/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.6801 - sparse_categorical_accuracy: 0.8259\n",
      "Epoch 7/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.6436 - sparse_categorical_accuracy: 0.8329\n",
      "Epoch 8/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.6104 - sparse_categorical_accuracy: 0.8383\n",
      "Epoch 9/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.5887 - sparse_categorical_accuracy: 0.8407\n",
      "Epoch 10/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.5673 - sparse_categorical_accuracy: 0.8437\n",
      "Epoch 11/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.5471 - sparse_categorical_accuracy: 0.8476\n",
      "Epoch 12/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.5302 - sparse_categorical_accuracy: 0.8511\n",
      "Epoch 13/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.5143 - sparse_categorical_accuracy: 0.8546\n",
      "Epoch 14/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.4999 - sparse_categorical_accuracy: 0.8562\n",
      "Epoch 15/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.4946 - sparse_categorical_accuracy: 0.8561\n",
      "Epoch 16/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.4794 - sparse_categorical_accuracy: 0.8603\n",
      "Epoch 17/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.4679 - sparse_categorical_accuracy: 0.8611\n",
      "Epoch 18/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.4569 - sparse_categorical_accuracy: 0.8615\n",
      "Epoch 19/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.4521 - sparse_categorical_accuracy: 0.8656\n",
      "Epoch 20/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.4468 - sparse_categorical_accuracy: 0.8652\n",
      "Epoch 21/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.4376 - sparse_categorical_accuracy: 0.8656\n",
      "Epoch 22/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.4311 - sparse_categorical_accuracy: 0.8655\n",
      "Epoch 23/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.4253 - sparse_categorical_accuracy: 0.8691\n",
      "Epoch 24/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.4211 - sparse_categorical_accuracy: 0.8690\n",
      "Epoch 25/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.4131 - sparse_categorical_accuracy: 0.8703\n",
      "Epoch 26/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.4064 - sparse_categorical_accuracy: 0.8695\n",
      "Epoch 27/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.4019 - sparse_categorical_accuracy: 0.8715\n",
      "Epoch 28/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.4015 - sparse_categorical_accuracy: 0.8711\n",
      "Epoch 29/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3980 - sparse_categorical_accuracy: 0.8730\n",
      "Epoch 30/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3918 - sparse_categorical_accuracy: 0.8732\n",
      "Epoch 31/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3887 - sparse_categorical_accuracy: 0.8731\n",
      "Epoch 32/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3832 - sparse_categorical_accuracy: 0.8756\n",
      "Epoch 33/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3852 - sparse_categorical_accuracy: 0.8751\n",
      "Epoch 34/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3798 - sparse_categorical_accuracy: 0.8758\n",
      "Epoch 35/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3781 - sparse_categorical_accuracy: 0.8758\n",
      "Epoch 36/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3753 - sparse_categorical_accuracy: 0.8767\n",
      "Epoch 37/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3728 - sparse_categorical_accuracy: 0.8772\n",
      "Epoch 38/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3675 - sparse_categorical_accuracy: 0.8761\n",
      "Epoch 39/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3729 - sparse_categorical_accuracy: 0.8748\n",
      "Epoch 40/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3659 - sparse_categorical_accuracy: 0.8765\n",
      "Epoch 41/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3645 - sparse_categorical_accuracy: 0.8769\n",
      "Epoch 42/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3616 - sparse_categorical_accuracy: 0.8783\n",
      "Epoch 43/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3581 - sparse_categorical_accuracy: 0.8805\n",
      "Epoch 44/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3628 - sparse_categorical_accuracy: 0.8780\n",
      "Epoch 45/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3612 - sparse_categorical_accuracy: 0.8781\n",
      "Epoch 46/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3567 - sparse_categorical_accuracy: 0.8797\n",
      "Epoch 47/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3564 - sparse_categorical_accuracy: 0.8782\n",
      "Epoch 48/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3572 - sparse_categorical_accuracy: 0.8787\n",
      "Epoch 49/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3557 - sparse_categorical_accuracy: 0.8804\n",
      "Epoch 50/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3495 - sparse_categorical_accuracy: 0.8790\n",
      "Epoch 51/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3514 - sparse_categorical_accuracy: 0.8801\n",
      "Epoch 52/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3539 - sparse_categorical_accuracy: 0.8788\n",
      "Epoch 53/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3554 - sparse_categorical_accuracy: 0.8774\n",
      "Epoch 54/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3482 - sparse_categorical_accuracy: 0.8790\n",
      "Epoch 55/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3472 - sparse_categorical_accuracy: 0.8807\n",
      "Epoch 56/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3477 - sparse_categorical_accuracy: 0.8796\n",
      "Epoch 57/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3416 - sparse_categorical_accuracy: 0.8821\n",
      "Epoch 58/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3423 - sparse_categorical_accuracy: 0.8819\n",
      "Epoch 59/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3447 - sparse_categorical_accuracy: 0.8801\n",
      "Epoch 60/60\n",
      "578/578 [==============================] - 4s 7ms/step - loss: 0.3429 - sparse_categorical_accuracy: 0.8821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20dd2d2fe80>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if OUTPUT_CLASSES == 2:\n",
    "    text_model.compile(loss=\"binary_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"accuracy\"])\n",
    "else:\n",
    "    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "text_model.fit(train_data, epochs=NB_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d6493f8-3c5e-457b-b39c-372080979f55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 6ms/step - loss: 1.1091 - sparse_categorical_accuracy: 0.8560\n",
      "60번 학습 :  [1.1091185808181763, 0.85595703125]\n"
     ]
    }
   ],
   "source": [
    "results = text_model.evaluate(test_data)\n",
    "print(\"60번 학습 : \", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6dc653-2111-4820-8b21-7ed9713afc9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_model.fit(train_data, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5f37da-ff9e-488d-b5e0-6dc1d20fe818",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = text_model.evaluate(test_data)\n",
    "print(\"13번 학습 : \", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51989cd6-9849-4351-b640-31bff66d923c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_model.fit(train_data, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5458f9e-217d-4d1e-9a1c-c25c634c4466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = text_model.evaluate(test_data)\n",
    "print(\"17번 학습 : \", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf143ad-c98f-4ba9-a197-1c005d59b133",
   "metadata": {},
   "source": [
    "## pred 는각각 61개 컬럼 라벨에서의 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b1782d4-1a23-4344-b769-e626ac3dcb02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = text_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "133e79f3-84b4-4b45-992f-fc5a7cef3f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 61)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "275e3806-ddde-4b03-8ba1-ba2458981326",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.45551949e-30, 0.00000000e+00, 2.00791066e-36, 3.90605325e-27,\n",
       "       4.25406924e-15, 6.34105322e-32, 0.00000000e+00, 1.00000000e+00,\n",
       "       2.14925038e-27, 4.54142815e-36, 0.00000000e+00, 2.03454402e-34,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.48511584e-37, 0.00000000e+00, 5.04656623e-33, 2.40916340e-16,\n",
       "       4.13925651e-24, 1.91866206e-27, 4.86637431e-20, 2.08883304e-17,\n",
       "       6.04481383e-25, 6.79868500e-22, 1.39233295e-18, 8.17786808e-25,\n",
       "       7.05953202e-25, 0.00000000e+00, 1.40108007e-35, 1.23969656e-30,\n",
       "       4.67063578e-28, 1.52123629e-26, 6.50525278e-34, 4.67524494e-16,\n",
       "       0.00000000e+00, 7.94162461e-28, 3.76042795e-35, 1.10912943e-25,\n",
       "       1.16339720e-30, 0.00000000e+00, 0.00000000e+00, 1.42133718e-20,\n",
       "       1.11330335e-35, 3.47610873e-17, 1.01790132e-36, 0.00000000e+00,\n",
       "       1.71528688e-17, 1.18546334e-26, 0.00000000e+00, 3.02889864e-32,\n",
       "       2.59298747e-18, 2.84224673e-28, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.35655806e-27, 1.01595031e-28,\n",
       "       1.46294374e-31], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d32926-b7d9-4a30-aa61-eb724528a207",
   "metadata": {},
   "source": [
    "# predicted_result 50개의 배치(배치 사이즈 : 32) 데이터 마다 예측 라벨링을 리스트에 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f942e5d-e068-4281-985f-171d08dd1179",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_result = []\n",
    "for j in range(64):\n",
    "    temp=[]\n",
    "    for i in range(32) :   \n",
    "        predicted_class = tf.argmax(pred[i+ j*32]).numpy() ## 가장 높은 확률의 라벨링 데이터를 구함\n",
    "        temp.append(predicted_class)\n",
    "    predicted_result.append(temp)\n",
    "        # print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3aa175fc-2d4e-41f5-8f1f-ad363c06d7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 8, 40, 57, 48, 24, 4, 24, 50, 24, 39, 39, 57, 19, 8, 24, 24, 8, 56, 24, 24, 50, 24, 24, 23, 58, 8, 23, 39, 19, 39, 50]\n",
      "[50, 45, 26, 58, 8, 23, 5, 58, 57, 4, 23, 8, 25, 23, 24, 43, 7, 23, 8, 24, 23, 17, 44, 24, 19, 17, 46, 26, 23, 41, 24, 23]\n",
      "[24, 8, 39, 24, 44, 4, 26, 46, 4, 0, 8, 46, 39, 48, 7, 54, 4, 44, 50, 23, 8, 39, 17, 57, 19, 26, 17, 57, 44, 24, 24, 24]\n",
      "[54, 7, 0, 8, 24, 17, 26, 57, 4, 44, 8, 4, 17, 57, 4, 44, 45, 5, 57, 46, 4, 44, 24, 4, 39, 39, 10, 23, 44, 24, 17, 44]\n",
      "[39, 24, 50, 46, 57, 39, 17, 24, 24, 24, 40, 39, 17, 58, 23, 8, 4, 39, 40, 46, 24, 7, 19, 22, 45, 24, 55, 40, 42, 42, 25, 4]\n",
      "[24, 58, 24, 42, 42, 40, 10, 58, 50, 57, 4, 4, 57, 20, 24, 40, 51, 25, 58, 58, 45, 43, 26, 40, 51, 8, 57, 0, 24, 48, 25, 24]\n",
      "[42, 39, 4, 58, 40, 42, 42, 23, 51, 40, 8, 24, 44, 46, 29, 23, 44, 24, 24, 41, 57, 24, 24, 24, 58, 7, 4, 7, 8, 4, 29, 51]\n",
      "[24, 15, 57, 19, 19, 44, 24, 45, 24, 58, 7, 55, 19, 23, 40, 18, 8, 57, 58, 4, 42, 4, 42, 39, 40, 58, 24, 46, 55, 0, 19, 4]\n",
      "[4, 39, 43, 46, 57, 24, 45, 58, 58, 24, 45, 24, 24, 24, 33, 18, 24, 24, 24, 21, 8, 37, 41, 24, 26, 58, 4, 40, 15, 50, 24, 8]\n",
      "[41, 8, 40, 42, 0, 40, 24, 12, 24, 24, 0, 8, 4, 35, 58, 45, 40, 51, 24, 51, 49, 24, 50, 57, 51, 24, 24, 46, 10, 45, 40, 58]\n",
      "[42, 4, 58, 24, 35, 24, 7, 45, 48, 4, 19, 40, 40, 24, 8, 12, 40, 40, 49, 24, 58, 25, 23, 57, 40, 24, 24, 26, 40, 57, 40, 46]\n",
      "[24, 57, 24, 40, 10, 24, 24, 58, 24, 42, 8, 57, 24, 43, 25, 58, 0, 58, 57, 8, 4, 27, 58, 57, 45, 24, 8, 24, 46, 57, 51, 40]\n",
      "[58, 24, 51, 25, 46, 57, 40, 24, 4, 42, 50, 24, 24, 24, 46, 25, 26, 42, 44, 37, 48, 41, 45, 24, 34, 4, 34, 10, 56, 25, 22, 57]\n",
      "[46, 4, 23, 40, 30, 42, 24, 24, 33, 19, 24, 48, 43, 24, 4, 51, 24, 8, 40, 24, 50, 44, 40, 40, 19, 25, 39, 56, 4, 24, 42, 8]\n",
      "[40, 16, 57, 24, 59, 23, 44, 23, 24, 54, 40, 4, 5, 24, 24, 19, 44, 44, 44, 24, 35, 37, 24, 24, 20, 24, 24, 57, 4, 40, 40, 19]\n",
      "[24, 46, 24, 37, 20, 42, 24, 45, 19, 34, 4, 51, 22, 0, 24, 44, 50, 24, 45, 24, 18, 24, 58, 30, 4, 24, 8, 19, 42, 7, 8, 20]\n",
      "[49, 40, 50, 39, 24, 59, 58, 57, 18, 40, 45, 24, 34, 50, 51, 0, 8, 19, 58, 4, 23, 50, 24, 24, 24, 46, 13, 57, 4, 24, 24, 48]\n",
      "[25, 4, 40, 4, 24, 25, 19, 26, 24, 37, 48, 48, 24, 24, 57, 50, 40, 24, 57, 24, 24, 52, 44, 24, 50, 24, 24, 24, 45, 24, 4, 45]\n",
      "[25, 19, 41, 24, 25, 24, 7, 24, 57, 24, 57, 49, 40, 48, 46, 42, 34, 44, 24, 4, 24, 50, 39, 8, 58, 7, 24, 8, 7, 57, 23, 4]\n",
      "[0, 50, 25, 44, 19, 24, 24, 16, 44, 50, 24, 57, 16, 4, 19, 24, 51, 40, 48, 4, 40, 40, 30, 4, 58, 26, 24, 42, 18, 45, 34, 57]\n",
      "[35, 8, 41, 54, 24, 24, 19, 4, 4, 49, 40, 4, 24, 44, 8, 4, 40, 25, 33, 56, 8, 40, 34, 25, 44, 40, 24, 24, 4, 40, 24, 41]\n",
      "[42, 25, 4, 24, 46, 48, 19, 42, 8, 4, 50, 57, 24, 57, 40, 45, 19, 24, 4, 24, 10, 4, 46, 57, 57, 40, 25, 25, 8, 56, 40, 19]\n",
      "[40, 4, 26, 24, 57, 4, 24, 44, 51, 24, 0, 46, 44, 57, 54, 24, 41, 24, 19, 24, 24, 25, 22, 50, 20, 50, 25, 17, 24, 3, 24, 17]\n",
      "[24, 40, 4, 42, 24, 4, 24, 24, 8, 58, 44, 46, 8, 40, 7, 44, 24, 40, 24, 24, 52, 24, 24, 56, 24, 4, 39, 23, 39, 16, 24, 25]\n",
      "[25, 24, 24, 24, 24, 56, 4, 4, 57, 33, 8, 54, 24, 57, 24, 42, 25, 4, 17, 42, 24, 57, 4, 26, 58, 43, 25, 24, 46, 33, 24, 8]\n",
      "[24, 24, 24, 57, 23, 24, 24, 33, 18, 24, 9, 24, 39, 4, 24, 24, 8, 58, 57, 24, 48, 56, 48, 52, 2, 4, 4, 42, 24, 4, 4, 40]\n",
      "[24, 2, 57, 19, 4, 24, 26, 24, 24, 39, 43, 25, 23, 33, 24, 57, 24, 23, 39, 8, 40, 24, 22, 44, 22, 3, 24, 24, 23, 24, 24, 22]\n",
      "[0, 52, 33, 24, 52, 46, 4, 0, 50, 24, 57, 46, 8, 37, 24, 24, 8, 24, 40, 19, 34, 23, 24, 4, 4, 24, 24, 19, 24, 50, 33, 43]\n",
      "[60, 0, 46, 24, 12, 45, 39, 10, 22, 19, 44, 46, 55, 24, 50, 39, 24, 46, 45, 8, 46, 18, 4, 43, 12, 26, 4, 24, 24, 24, 17, 24]\n",
      "[24, 12, 14, 22, 40, 8, 24, 46, 24, 33, 26, 4, 33, 22, 24, 39, 46, 42, 46, 50, 41, 15, 4, 23, 48, 24, 50, 24, 24, 4, 30, 8]\n",
      "[34, 24, 33, 20, 4, 40, 23, 44, 24, 22, 23, 0, 45, 24, 18, 49, 56, 19, 43, 24, 43, 8, 42, 40, 24, 46, 24, 24, 24, 26, 22, 56]\n",
      "[39, 24, 24, 43, 48, 55, 46, 40, 24, 23, 4, 22, 57, 24, 8, 49, 25, 8, 24, 4, 57, 23, 24, 46, 24, 46, 37, 24, 58, 26, 37, 23]\n",
      "[22, 24, 24, 8, 46, 4, 24, 25, 33, 4, 2, 24, 46, 9, 24, 43, 24, 19, 24, 58, 4, 23, 4, 37, 48, 24, 40, 40, 19, 24, 56, 45]\n",
      "[8, 23, 4, 46, 57, 60, 24, 8, 23, 19, 24, 43, 58, 42, 51, 24, 46, 45, 44, 39, 55, 44, 40, 24, 40, 40, 45, 24, 46, 24, 24, 24]\n",
      "[39, 44, 43, 58, 24, 25, 48, 4, 40, 45, 49, 24, 4, 46, 33, 22, 40, 4, 8, 57, 8, 40, 46, 4, 44, 24, 26, 58, 4, 8, 24, 19]\n",
      "[4, 45, 8, 24, 24, 40, 58, 50, 48, 24, 24, 4, 26, 46, 42, 42, 24, 8, 40, 46, 24, 24, 41, 19, 24, 4, 58, 8, 24, 39, 19, 23]\n",
      "[24, 48, 39, 25, 28, 48, 31, 26, 24, 18, 4, 24, 56, 48, 8, 22, 24, 31, 4, 40, 24, 50, 39, 37, 41, 24, 46, 4, 24, 42, 36, 8]\n",
      "[35, 24, 24, 4, 44, 46, 24, 33, 24, 4, 24, 33, 24, 48, 40, 24, 56, 49, 24, 18, 48, 19, 55, 19, 49, 19, 40, 8, 24, 25, 24, 46]\n",
      "[24, 48, 37, 24, 19, 24, 43, 46, 23, 19, 46, 42, 37, 40, 18, 24, 37, 45, 33, 4, 24, 23, 8, 26, 40, 57, 24, 40, 4, 24, 35, 24]\n",
      "[50, 57, 24, 37, 24, 24, 24, 24, 24, 19, 4, 41, 24, 20, 24, 24, 24, 20, 33, 40, 33, 42, 24, 13, 25, 12, 23, 46, 22, 24, 40, 44]\n",
      "[24, 4, 24, 24, 40, 58, 40, 58, 12, 40, 24, 22, 24, 4, 15, 44, 24, 8, 24, 36, 26, 24, 26, 46, 46, 33, 57, 60, 30, 24, 22, 8]\n",
      "[57, 24, 40, 24, 24, 24, 4, 33, 24, 23, 33, 42, 15, 33, 40, 31, 24, 22, 42, 55, 56, 4, 19, 24, 24, 4, 19, 39, 26, 19, 46, 23]\n",
      "[8, 4, 4, 39, 23, 22, 4, 23, 37, 8, 24, 57, 22, 58, 57, 46, 24, 23, 24, 23, 4, 4, 19, 45, 4, 37, 24, 13, 18, 37, 40, 24]\n",
      "[23, 24, 24, 40, 46, 57, 40, 24, 50, 60, 58, 24, 48, 24, 26, 33, 46, 40, 24, 4, 8, 40, 24, 24, 4, 30, 12, 37, 26, 12, 24, 43]\n",
      "[58, 39, 46, 39, 24, 25, 40, 40, 4, 24, 24, 24, 33, 24, 24, 24, 40, 33, 8, 23, 25, 12, 0, 24, 8, 19, 24, 43, 4, 24, 4, 45]\n",
      "[24, 15, 46, 29, 12, 24, 4, 24, 42, 24, 46, 46, 23, 4, 24, 43, 24, 57, 40, 23, 24, 24, 4, 24, 46, 57, 24, 39, 25, 46, 45, 24]\n",
      "[46, 23, 46, 7, 46, 23, 4, 4, 22, 24, 24, 26, 41, 8, 40, 24, 24, 19, 31, 57, 23, 42, 45, 24, 46, 57, 4, 4, 33, 40, 22, 48]\n",
      "[44, 24, 56, 25, 24, 50, 24, 24, 33, 8, 40, 4, 24, 43, 30, 50, 24, 43, 26, 43, 8, 19, 33, 19, 4, 22, 40, 4, 34, 4, 4, 46]\n",
      "[45, 24, 24, 24, 24, 40, 22, 43, 4, 24, 55, 24, 46, 4, 24, 8, 40, 24, 8, 25, 42, 33, 22, 24, 39, 33, 44, 49, 0, 9, 22, 26]\n",
      "[24, 24, 57, 4, 34, 33, 24, 46, 4, 8, 50, 56, 24, 39, 4, 37, 4, 23, 25, 48, 24, 20, 39, 0, 24, 50, 57, 23, 40, 4, 57, 23]\n",
      "[46, 24, 24, 46, 19, 24, 22, 8, 24, 42, 39, 58, 24, 40, 23, 57, 46, 48, 45, 40, 58, 10, 39, 45, 24, 49, 52, 39, 20, 38, 50, 10]\n",
      "[8, 20, 40, 41, 42, 19, 4, 57, 50, 25, 29, 42, 24, 24, 42, 24, 20, 8, 40, 41, 52, 38, 56, 42, 4, 24, 24, 48, 25, 51, 4, 4]\n",
      "[50, 41, 40, 4, 24, 24, 58, 50, 50, 10, 41, 26, 24, 24, 40, 41, 24, 58, 38, 46, 26, 24, 45, 24, 10, 24, 23, 46, 40, 37, 24, 34]\n",
      "[40, 57, 58, 48, 52, 44, 56, 19, 44, 24, 10, 44, 37, 40, 44, 44, 4, 57, 24, 5, 4, 34, 4, 24, 50, 43, 24, 24, 40, 23, 56, 46]\n",
      "[39, 24, 4, 41, 24, 44, 4, 24, 24, 10, 4, 40, 58, 46, 50, 24, 10, 44, 40, 49, 24, 24, 24, 10, 24, 23, 24, 20, 39, 24, 56, 50]\n",
      "[24, 4, 24, 17, 24, 43, 45, 57, 59, 26, 49, 40, 24, 19, 56, 46, 24, 29, 40, 24, 46, 40, 49, 50, 24, 10, 0, 24, 0, 40, 46, 24]\n",
      "[56, 22, 48, 46, 4, 41, 24, 24, 0, 20, 31, 10, 36, 24, 8, 4, 24, 40, 40, 58, 24, 40, 42, 20, 58, 57, 24, 4, 42, 10, 24, 24]\n",
      "[42, 10, 24, 4, 50, 45, 44, 7, 58, 40, 20, 46, 49, 40, 52, 17, 24, 57, 19, 57, 20, 24, 40, 24, 26, 37, 4, 46, 50, 10, 44, 24]\n",
      "[20, 26, 4, 56, 24, 8, 26, 37, 23, 44, 44, 7, 4, 42, 50, 37, 48, 24, 39, 48, 24, 41, 40, 10, 41, 24, 4, 10, 45, 24, 23, 44]\n",
      "[34, 48, 60, 40, 40, 19, 37, 46, 40, 24, 24, 4, 24, 40, 46, 40, 37, 40, 4, 41, 24, 4, 4, 24, 24, 24, 42, 24, 56, 19, 4, 44]\n",
      "[4, 24, 18, 26, 10, 20, 4, 24, 8, 10, 49, 42, 4, 52, 40, 42, 16, 10, 8, 38, 44, 41, 4, 56, 44, 10, 23, 40, 40, 40, 57, 25]\n",
      "[4, 56, 40, 33, 24, 39, 24, 50, 39, 24, 17, 24, 46, 58, 8, 44, 10, 24, 20, 24, 10, 37, 24, 23, 4, 4, 19, 56, 23, 34, 46, 22]\n",
      "[42, 41, 40, 46, 40, 4, 31, 4, 24, 44, 42, 38, 46, 24, 43, 57, 56, 4, 49, 57, 33, 24, 44, 23, 24, 50, 37, 40, 20, 34, 19, 19]\n",
      "[10, 40, 10, 48, 48, 31, 19, 57, 24, 40, 40, 8, 39, 24, 42, 23, 20, 10, 48, 24, 40, 57, 42, 50, 48, 4, 44, 50, 46, 45, 46, 45]\n"
     ]
    }
   ],
   "source": [
    "for lis in predicted_result:\n",
    "    print(lis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d693f8-3ab6-4a79-990e-cc372cc1a8e9",
   "metadata": {},
   "source": [
    "# true_result : 테스트 데이터에서의 실제 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58bd7f02-f502-4e2b-86b0-53332ea15776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_result =[]\n",
    "for inputs, targets in test_data.take(64):\n",
    "    # 첫 번째 데이터 샘플에 대한 입력(inputs)과 라벨(targets)을 확인\n",
    "\n",
    "    # Convert EagerTensor to numpy array\n",
    "    targets_numpy = np.array(targets)\n",
    "\n",
    "    # Convert numpy array to list\n",
    "    targets_list = targets_numpy.tolist()\n",
    "    true_result.append(targets_list)\n",
    "    # print(\"Targets:\", targets_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "491ed6c6-4952-4d46-a51b-2c989fd68d4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 8, 2, 57, 48, 10, 4, 24, 50, 24, 39, 39, 57, 19, 8, 57, 24, 8, 0, 57, 24, 50, 10, 24, 23, 58, 8, 23, 39, 44, 39, 50]\n",
      "[50, 45, 7, 58, 8, 23, 5, 24, 57, 4, 17, 8, 27, 17, 24, 43, 7, 23, 8, 24, 23, 17, 44, 18, 19, 17, 46, 26, 17, 41, 24, 23]\n",
      "[40, 8, 39, 40, 44, 24, 7, 46, 4, 0, 8, 46, 39, 48, 7, 54, 4, 44, 50, 23, 8, 39, 17, 57, 19, 7, 17, 52, 44, 24, 24, 24]\n",
      "[54, 7, 0, 8, 24, 17, 7, 57, 4, 44, 8, 4, 17, 57, 4, 44, 45, 24, 57, 46, 4, 44, 24, 4, 39, 39, 10, 23, 44, 40, 17, 44]\n",
      "[39, 24, 50, 46, 57, 39, 17, 24, 24, 24, 40, 39, 17, 58, 23, 8, 4, 39, 40, 46, 24, 7, 19, 22, 18, 24, 55, 40, 54, 42, 25, 4]\n",
      "[24, 58, 24, 42, 42, 40, 10, 58, 50, 57, 4, 4, 57, 20, 24, 40, 51, 25, 58, 58, 42, 43, 24, 40, 51, 8, 57, 0, 24, 48, 25, 24]\n",
      "[54, 39, 4, 58, 40, 42, 42, 50, 51, 40, 8, 24, 44, 46, 29, 50, 44, 24, 24, 41, 57, 24, 24, 24, 58, 7, 4, 7, 8, 4, 29, 51]\n",
      "[24, 9, 57, 19, 19, 44, 24, 18, 24, 58, 7, 55, 19, 23, 40, 2, 8, 57, 58, 4, 54, 4, 42, 39, 40, 58, 24, 46, 55, 0, 19, 4]\n",
      "[4, 39, 43, 46, 57, 24, 45, 58, 58, 7, 45, 24, 24, 24, 24, 26, 24, 24, 24, 21, 8, 37, 41, 40, 24, 58, 4, 40, 9, 50, 24, 8]\n",
      "[41, 8, 40, 54, 0, 40, 24, 12, 40, 4, 0, 8, 4, 17, 58, 45, 40, 51, 24, 51, 49, 24, 50, 57, 51, 24, 24, 46, 10, 45, 40, 58]\n",
      "[42, 39, 58, 24, 24, 24, 7, 45, 20, 4, 19, 40, 40, 24, 8, 12, 40, 40, 49, 24, 58, 25, 24, 57, 40, 24, 40, 26, 40, 57, 26, 46]\n",
      "[24, 57, 40, 40, 10, 24, 24, 58, 24, 54, 8, 57, 24, 43, 25, 58, 0, 58, 57, 8, 4, 27, 58, 57, 18, 42, 8, 24, 46, 57, 51, 40]\n",
      "[58, 24, 51, 25, 12, 57, 24, 24, 4, 42, 50, 24, 58, 24, 12, 25, 26, 42, 44, 37, 40, 41, 45, 24, 34, 4, 34, 10, 56, 25, 22, 57]\n",
      "[46, 4, 57, 40, 30, 42, 24, 24, 33, 19, 24, 24, 43, 24, 4, 51, 20, 8, 30, 24, 50, 44, 40, 40, 19, 25, 39, 25, 4, 24, 42, 8]\n",
      "[40, 16, 57, 24, 17, 36, 44, 23, 24, 54, 40, 4, 45, 25, 24, 19, 44, 44, 44, 24, 17, 37, 24, 24, 19, 24, 40, 57, 12, 40, 40, 19]\n",
      "[24, 46, 40, 37, 20, 42, 24, 19, 12, 34, 4, 51, 22, 24, 24, 20, 50, 24, 45, 24, 18, 40, 58, 24, 4, 40, 8, 19, 42, 7, 8, 2]\n",
      "[49, 40, 50, 39, 40, 17, 58, 57, 26, 40, 8, 40, 34, 50, 51, 24, 8, 19, 58, 4, 23, 50, 19, 40, 26, 46, 13, 57, 4, 41, 24, 48]\n",
      "[25, 4, 40, 4, 40, 27, 19, 57, 24, 37, 48, 17, 24, 24, 57, 44, 40, 24, 57, 40, 24, 52, 44, 40, 50, 33, 33, 24, 45, 24, 4, 45]\n",
      "[25, 19, 41, 24, 25, 40, 7, 24, 57, 24, 57, 49, 40, 48, 46, 42, 34, 44, 24, 4, 40, 50, 39, 8, 58, 7, 24, 8, 7, 57, 23, 4]\n",
      "[24, 50, 25, 44, 19, 33, 33, 16, 44, 50, 24, 57, 16, 4, 19, 40, 51, 40, 48, 4, 24, 40, 27, 4, 58, 57, 40, 50, 18, 45, 34, 57]\n",
      "[17, 8, 41, 24, 24, 40, 30, 4, 4, 49, 40, 4, 24, 44, 8, 4, 40, 25, 33, 56, 8, 40, 34, 25, 44, 40, 24, 24, 4, 40, 24, 41]\n",
      "[42, 25, 4, 24, 46, 17, 19, 42, 8, 4, 50, 57, 24, 57, 40, 45, 19, 24, 25, 24, 10, 4, 56, 57, 57, 40, 25, 25, 8, 56, 40, 19]\n",
      "[40, 4, 26, 24, 57, 4, 40, 44, 51, 24, 0, 46, 44, 57, 54, 24, 41, 24, 19, 58, 24, 25, 22, 50, 20, 50, 17, 17, 24, 3, 24, 17]\n",
      "[40, 40, 4, 42, 24, 4, 24, 24, 8, 58, 44, 46, 8, 40, 7, 44, 24, 40, 24, 40, 52, 24, 24, 56, 24, 4, 39, 23, 39, 16, 24, 25]\n",
      "[17, 24, 24, 44, 24, 26, 4, 4, 57, 33, 8, 54, 24, 57, 40, 42, 25, 4, 17, 42, 40, 57, 4, 12, 58, 43, 25, 40, 46, 33, 44, 8]\n",
      "[24, 24, 40, 57, 23, 24, 24, 33, 18, 24, 9, 40, 39, 4, 24, 24, 8, 58, 57, 40, 48, 25, 48, 24, 2, 4, 4, 42, 24, 4, 4, 40]\n",
      "[29, 2, 57, 19, 4, 56, 26, 24, 24, 39, 43, 25, 23, 33, 40, 52, 24, 23, 39, 8, 40, 24, 22, 44, 22, 3, 24, 24, 23, 24, 40, 22]\n",
      "[0, 24, 33, 20, 17, 12, 4, 39, 50, 40, 57, 46, 8, 37, 24, 40, 8, 24, 40, 19, 34, 3, 17, 4, 4, 24, 24, 19, 17, 50, 33, 43]\n",
      "[28, 0, 46, 40, 12, 45, 39, 10, 22, 19, 44, 46, 55, 24, 50, 39, 40, 46, 45, 8, 46, 18, 4, 43, 12, 12, 4, 40, 24, 24, 17, 24]\n",
      "[24, 12, 14, 22, 40, 8, 40, 46, 29, 33, 26, 4, 33, 22, 24, 39, 46, 42, 46, 50, 41, 15, 4, 23, 48, 24, 50, 24, 40, 4, 50, 8]\n",
      "[34, 24, 33, 20, 4, 40, 23, 44, 24, 22, 27, 39, 45, 24, 18, 49, 56, 19, 43, 24, 43, 8, 42, 40, 24, 46, 40, 24, 24, 26, 22, 56]\n",
      "[39, 24, 24, 43, 48, 55, 46, 40, 24, 23, 4, 22, 57, 24, 8, 49, 25, 8, 40, 4, 57, 23, 24, 46, 24, 46, 37, 24, 58, 26, 37, 23]\n",
      "[22, 24, 24, 8, 46, 4, 40, 25, 33, 4, 2, 24, 46, 9, 40, 43, 24, 19, 17, 58, 4, 23, 4, 37, 48, 24, 40, 45, 19, 24, 56, 45]\n",
      "[8, 23, 4, 46, 57, 60, 56, 8, 23, 19, 40, 43, 58, 42, 51, 24, 46, 45, 44, 39, 55, 44, 40, 40, 40, 40, 0, 40, 46, 24, 40, 40]\n",
      "[39, 44, 43, 58, 40, 25, 48, 4, 40, 45, 49, 40, 4, 46, 33, 22, 40, 4, 8, 57, 8, 40, 46, 4, 44, 24, 12, 58, 4, 8, 24, 19]\n",
      "[4, 45, 8, 24, 24, 40, 58, 50, 48, 24, 24, 4, 26, 46, 42, 42, 24, 8, 40, 46, 24, 24, 41, 19, 24, 4, 58, 8, 24, 39, 19, 23]\n",
      "[24, 48, 39, 25, 28, 48, 31, 12, 24, 18, 4, 24, 56, 48, 8, 22, 40, 31, 4, 40, 40, 50, 39, 37, 41, 24, 46, 4, 24, 42, 56, 8]\n",
      "[35, 40, 40, 4, 44, 46, 24, 33, 44, 4, 40, 33, 40, 48, 40, 40, 56, 49, 24, 18, 48, 19, 55, 19, 49, 19, 40, 8, 40, 25, 40, 46]\n",
      "[24, 34, 37, 24, 19, 24, 43, 46, 23, 19, 46, 42, 37, 40, 18, 24, 24, 45, 33, 4, 24, 23, 8, 26, 40, 57, 24, 40, 4, 24, 35, 40]\n",
      "[50, 57, 40, 17, 24, 24, 40, 24, 24, 24, 4, 2, 24, 20, 40, 24, 24, 20, 33, 40, 33, 42, 24, 13, 25, 12, 23, 46, 22, 24, 40, 44]\n",
      "[24, 4, 40, 24, 40, 58, 40, 58, 12, 40, 40, 22, 40, 4, 15, 44, 40, 8, 24, 19, 7, 40, 26, 46, 46, 33, 19, 60, 30, 40, 22, 8]\n",
      "[57, 24, 40, 40, 24, 40, 4, 33, 24, 23, 33, 42, 15, 33, 40, 31, 24, 22, 42, 55, 2, 4, 19, 24, 24, 4, 19, 39, 26, 19, 46, 23]\n",
      "[8, 4, 4, 39, 23, 22, 4, 23, 37, 8, 40, 57, 22, 58, 57, 46, 24, 23, 40, 23, 4, 4, 19, 45, 4, 37, 24, 13, 18, 37, 40, 24]\n",
      "[23, 24, 40, 40, 46, 57, 40, 24, 50, 28, 58, 24, 48, 40, 26, 33, 46, 40, 24, 4, 8, 40, 40, 24, 4, 30, 12, 37, 24, 12, 40, 43]\n",
      "[58, 39, 46, 39, 41, 25, 40, 40, 4, 24, 40, 40, 33, 40, 24, 24, 40, 33, 8, 23, 25, 12, 0, 40, 8, 19, 24, 43, 4, 40, 4, 45]\n",
      "[24, 15, 46, 29, 12, 24, 4, 24, 42, 40, 12, 46, 23, 4, 44, 43, 40, 57, 40, 23, 40, 24, 4, 24, 46, 57, 24, 39, 25, 46, 33, 24]\n",
      "[46, 23, 46, 7, 46, 23, 4, 4, 22, 40, 40, 26, 41, 8, 40, 24, 24, 19, 31, 57, 23, 42, 45, 40, 46, 57, 4, 4, 33, 40, 22, 48]\n",
      "[44, 24, 56, 25, 24, 50, 23, 40, 33, 8, 40, 4, 24, 43, 24, 50, 40, 43, 26, 43, 8, 19, 33, 19, 4, 22, 40, 4, 34, 4, 4, 46]\n",
      "[45, 24, 24, 24, 40, 40, 22, 43, 4, 24, 19, 40, 46, 4, 15, 8, 40, 40, 8, 25, 42, 33, 22, 40, 39, 33, 57, 49, 24, 9, 22, 25]\n",
      "[24, 40, 57, 4, 34, 33, 40, 46, 4, 8, 50, 56, 24, 39, 4, 37, 4, 23, 25, 48, 44, 20, 39, 0, 24, 50, 19, 23, 40, 4, 57, 23]\n",
      "[46, 40, 40, 46, 19, 24, 22, 8, 20, 57, 39, 25, 40, 40, 23, 57, 46, 48, 45, 40, 58, 10, 39, 45, 24, 19, 52, 39, 20, 38, 50, 10]\n",
      "[8, 20, 40, 41, 42, 19, 4, 57, 50, 25, 29, 42, 44, 24, 30, 24, 20, 8, 40, 41, 24, 38, 56, 42, 4, 24, 24, 48, 25, 51, 4, 4]\n",
      "[50, 41, 40, 4, 4, 24, 58, 50, 50, 10, 41, 26, 24, 24, 24, 41, 24, 58, 38, 46, 26, 20, 45, 24, 10, 35, 23, 46, 40, 37, 24, 34]\n",
      "[40, 57, 58, 48, 24, 44, 3, 19, 44, 24, 10, 44, 37, 40, 44, 44, 4, 57, 24, 5, 4, 34, 4, 24, 50, 43, 24, 24, 40, 23, 56, 46]\n",
      "[39, 24, 4, 41, 40, 44, 2, 40, 24, 10, 4, 40, 58, 46, 50, 24, 10, 44, 40, 49, 24, 24, 24, 10, 24, 52, 24, 20, 39, 24, 56, 50]\n",
      "[24, 4, 24, 56, 24, 43, 45, 30, 24, 26, 49, 40, 40, 19, 56, 46, 24, 29, 40, 24, 46, 40, 49, 50, 24, 10, 0, 24, 0, 40, 46, 24]\n",
      "[56, 22, 48, 46, 4, 41, 44, 24, 0, 20, 31, 10, 56, 24, 8, 4, 24, 40, 40, 58, 26, 40, 42, 20, 58, 57, 24, 4, 42, 10, 24, 24]\n",
      "[42, 10, 24, 4, 50, 45, 44, 7, 58, 40, 20, 46, 49, 45, 57, 24, 24, 30, 19, 57, 20, 24, 40, 24, 40, 37, 4, 46, 50, 10, 44, 24]\n",
      "[41, 26, 4, 56, 24, 8, 26, 37, 23, 44, 44, 7, 4, 42, 50, 37, 48, 24, 39, 48, 24, 41, 40, 10, 41, 24, 4, 10, 45, 24, 23, 44]\n",
      "[34, 48, 60, 40, 40, 19, 5, 46, 40, 24, 24, 4, 24, 40, 46, 40, 37, 40, 4, 41, 24, 4, 4, 24, 40, 24, 42, 24, 56, 24, 4, 44]\n",
      "[4, 24, 17, 26, 10, 20, 4, 24, 8, 10, 49, 42, 4, 52, 40, 42, 16, 10, 8, 38, 44, 41, 4, 56, 44, 10, 23, 40, 40, 40, 57, 25]\n",
      "[4, 56, 40, 35, 24, 39, 24, 50, 39, 24, 17, 24, 46, 58, 8, 44, 10, 24, 20, 24, 10, 37, 24, 23, 4, 4, 19, 37, 23, 34, 46, 22]\n",
      "[42, 41, 40, 46, 40, 4, 31, 4, 24, 44, 42, 38, 46, 24, 52, 57, 56, 4, 49, 57, 35, 24, 44, 23, 24, 50, 37, 40, 20, 34, 19, 19]\n",
      "[10, 40, 10, 48, 48, 31, 33, 57, 24, 24, 40, 8, 39, 24, 42, 23, 20, 10, 48, 52, 40, 57, 42, 50, 48, 4, 44, 50, 46, 45, 46, 45]\n"
     ]
    }
   ],
   "source": [
    "for lis in true_result:\n",
    "    print(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1e02e51-dc3c-4a01-b98c-57fc06cacbcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41c47476-8904-4f22-8d80-e0923c6aa0e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7877168539613285\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 score\n",
    "f1 = f1_score([item for sublist in true_result for item in sublist],\n",
    "              [item for sublist in predicted_result for item in sublist], average='macro')\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7056a6b9-d8f4-4970-8531-684f4ca15cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.79        21\n",
      "           2       0.33      1.00      0.50         3\n",
      "           3       0.50      1.00      0.67         2\n",
      "           4       0.99      0.97      0.98       172\n",
      "           5       0.67      0.50      0.57         4\n",
      "           7       0.74      1.00      0.85        17\n",
      "           8       0.99      1.00      0.99        86\n",
      "           9       0.60      1.00      0.75         3\n",
      "          10       0.94      1.00      0.97        31\n",
      "          12       0.52      1.00      0.69        11\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       0.80      0.67      0.73         6\n",
      "          16       1.00      1.00      1.00         5\n",
      "          17       0.44      0.88      0.58        16\n",
      "          18       0.69      0.69      0.69        13\n",
      "          19       0.88      0.90      0.89        62\n",
      "          20       0.76      0.86      0.81        22\n",
      "          21       1.00      1.00      1.00         1\n",
      "          22       1.00      1.00      1.00        31\n",
      "          23       0.98      0.84      0.90        67\n",
      "          24       0.91      0.68      0.78       466\n",
      "          25       0.86      0.90      0.88        42\n",
      "          26       0.78      0.57      0.66        37\n",
      "          27       0.20      1.00      0.33         1\n",
      "          28       0.33      1.00      0.50         1\n",
      "          29       0.71      1.00      0.83         5\n",
      "          30       0.38      0.43      0.40         7\n",
      "          31       1.00      1.00      1.00         7\n",
      "          33       0.84      0.91      0.87        34\n",
      "          34       0.94      1.00      0.97        16\n",
      "          35       0.40      0.33      0.36         6\n",
      "          36       0.00      0.00      0.00         3\n",
      "          37       0.96      0.89      0.93        28\n",
      "          38       1.00      1.00      1.00         5\n",
      "          39       0.94      1.00      0.97        50\n",
      "          40       0.55      0.94      0.70       141\n",
      "          41       0.89      0.96      0.93        26\n",
      "          42       0.96      0.85      0.90        55\n",
      "          43       1.00      0.96      0.98        26\n",
      "          44       0.87      0.97      0.91        60\n",
      "          45       0.92      0.80      0.86        41\n",
      "          46       1.00      0.95      0.97        91\n",
      "          48       1.00      0.85      0.92        39\n",
      "          49       1.00      0.94      0.97        18\n",
      "          50       0.93      0.98      0.95        52\n",
      "          51       1.00      1.00      1.00        16\n",
      "          52       0.44      0.40      0.42        10\n",
      "          54       0.50      0.83      0.62         6\n",
      "          55       1.00      0.89      0.94         9\n",
      "          56       0.78      0.75      0.76        28\n",
      "          57       0.90      0.93      0.92        82\n",
      "          58       0.96      0.96      0.96        55\n",
      "          59       0.00      0.00      0.00         3\n",
      "          60       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.86      2048\n",
      "   macro avg       0.78      0.84      0.79      2048\n",
      "weighted avg       0.88      0.86      0.86      2048\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report([item for sublist in predicted_result for item in sublist],\n",
    "                            [item for sublist in true_result for item in sublist]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
