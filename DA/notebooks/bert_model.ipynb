{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "261a7657-6dcc-4c74-846b-7753ca0445d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4859b907-8e49-4ce1-8d99-fded5eeccd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca2a05c4-57cd-4915-ab36-49aa6b0c6d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34205099-9c8f-4da3-8d26-468721d091db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # GPU 디바이스 목록 가져오기\n",
    "# gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# if len(gpu_devices) > 0:\n",
    "#     print(\"사용 가능한 GPU가 있습니다.\")\n",
    "#     for device in gpu_devices:\n",
    "#         print(\"GPU 디바이스 이름:\", device.name)\n",
    "# else:\n",
    "#     print(\"사용 가능한 GPU가 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fac9baf-fc45-4766-82be-c6d50dfd830e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install bert-for-tf2\n",
    "# !pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8033901a-87dc-42b1-aaf1-2cda85d9d3d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a242748-4045-47c6-8c1c-c61acba156f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/raw_postpro.csv') # 오류가나면 추가해주세요 .encoding = 'cp949'\n",
    "# 컬럼 삭제\n",
    "df = data.drop(['청구서번호','No.',  '선박입고','완료 여부','리드타임_음수제거','청구량','견적','견적수량','견적화폐','견적단가','발주번호','발주','발주수량','발주금액','미입고 기간','리드타임','창고입고','창고입고수량','입고창고','창고출고','창고출고수량','출고선박','출고운반선','선박입고','선박입고수량','완료 여부'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8f79718-2f3e-457a-bbf5-d8394f490994",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_list = ['COMPRESSOR', 'SEAT', 'TURBINE', 'LINE', 'ANODES', 'DAMPER', 'CARD', 'BELT', 'ARM', 'SWITCH',\n",
    " 'CLIP', 'BATTERY', 'ADAPTER', 'TOOL', 'CONTROL', 'BRAKE', 'TRANSFORMER', 'WINCH']\n",
    "df = df[~df['key2'].isin(delete_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e7e51b2-e8d8-48c9-b1a7-0fa03ab9e002",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19367 entries, 0 to 20516\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Subject      19367 non-null  object\n",
      " 1   Machinery    19367 non-null  object\n",
      " 2   Assembly     19367 non-null  object\n",
      " 3   청구품목         19367 non-null  object\n",
      " 4   Part No.1    19367 non-null  object\n",
      " 5   Part No.2    19367 non-null  object\n",
      " 6   key1         19367 non-null  object\n",
      " 7   key2         19367 non-null  object\n",
      " 8   발주처          19367 non-null  object\n",
      " 9   D/T          19367 non-null  object\n",
      " 10  Control No.  19367 non-null  object\n",
      " 11  leadtime     19367 non-null  int64 \n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0ac12f6-2aec-4362-b507-d8db659ddb7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[['청구품목','발주처','Machinery', 'Assembly' , \"key1\",'key2',\"Part No.1\", \"Part No.2\"]]\n",
    "# 'Machinery', 'Assembly', '청구품목', 'Part No.1', 'Part No.2', 'key1', '발주처'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfa338bd-3298-430c-9534-1f8ddc5a391f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoders = {}  # 각 열에 대한 LabelEncoder를 저장하기 위한 딕셔너리\n",
    "columns_to_encode = ['key2']  # 인코딩을 수행할 열의 이름 리스트\n",
    "\n",
    "for column in columns_to_encode:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df[column])\n",
    "    label_encoders[column] = le # 딕셔너리에 저장\n",
    "    df[column+\"_encoded\"] = le.transform(df[column]) # 새로운 encoding 된 컬럼 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd8e6c31-6c1d-46f0-ad58-7ab1ab285a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(['key2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1d21278-dd5e-4229-9b49-159058e996bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19367 entries, 0 to 20516\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   청구품목          19367 non-null  object\n",
      " 1   발주처           19367 non-null  object\n",
      " 2   Machinery     19367 non-null  object\n",
      " 3   Assembly      19367 non-null  object\n",
      " 4   key1          19367 non-null  object\n",
      " 5   Part No.1     19367 non-null  object\n",
      " 6   Part No.2     19367 non-null  object\n",
      " 7   key2_encoded  19367 non-null  int32 \n",
      "dtypes: int32(1), object(7)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1644800d-98cf-459d-9811-a594db7e7bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# text = df[[ '청구품목', '발주처','Machinery', 'Assembly' , \"key1\"]].apply(lambda row: ' '.join(row), axis=1)\n",
    "# df_text = df[['청구품목', '발주처', 'Machinery', 'Assembly']].apply(lambda row: ' '.join(row), axis=1).to_frame(name='text')\n",
    "# df_text = df[['청구품목', '발주처','Machinery' , \"key1\", \"Assembly\"]].apply(lambda row: ' '.join(row), axis=1).to_frame(name='text')\n",
    "\n",
    "df_text = df[['청구품목', '발주처','Machinery' , \"Part No.1\", \"Part No.2\"]].apply(lambda row: ' '.join(row), axis=1).to_frame(name='text')\n",
    "df_text['key2'] = df['key2_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed53b922-d2f1-473d-b234-b725c024dd66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>key2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEAL-O-RING-STOR HAEIN Coporation_Cheonan NO.1...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OIL COOLER &amp; LINES HAEIN Coporation_Cheonan NO...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WASHER HAEIN Coporation_Cheonan NO.2 GENERATOR...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOLT-HIGH TEMP HAEIN Coporation_Cheonan NO.1 G...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEAL HAEIN Coporation_Cheonan NO.1 GENERATOR E...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CORE CHARGES FOR CYLINDER PACK AS HAEIN Copora...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PUMP GP-F TFR-REMAN HAEIN Coporation_Cheonan N...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.1...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.3...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.3...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.1...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.1...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.3...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IMPELLER (주)정원펌프 NO.1 CONDENSER PUMP 3 0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SELF-ALIGNING ROLLER BEARING 대동베아링상사 BOW THRUS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TAPERED ROLLER BEARING 대동베아링상사 BOW THRUSTER 5....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SELF-ALIGNING ROLLER BEARING 대동베아링상사 BOW THRUS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TAPERED ROLLER BEARING 대동베아링상사 BOW THRUSTER 7....</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EXHUAST GAS TEMP. INDICATOR, P5 PIRIOU NAVAL S...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EXHAUST GAS TEMPERATURE INDICATOR 0 TO 700℃ PI...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  key2\n",
       "0   SEAL-O-RING-STOR HAEIN Coporation_Cheonan NO.1...     8\n",
       "1   OIL COOLER & LINES HAEIN Coporation_Cheonan NO...     8\n",
       "2   WASHER HAEIN Coporation_Cheonan NO.2 GENERATOR...     8\n",
       "3   BOLT-HIGH TEMP HAEIN Coporation_Cheonan NO.1 G...     8\n",
       "4   SEAL HAEIN Coporation_Cheonan NO.1 GENERATOR E...     8\n",
       "5   CORE CHARGES FOR CYLINDER PACK AS HAEIN Copora...     8\n",
       "6   PUMP GP-F TFR-REMAN HAEIN Coporation_Cheonan N...     8\n",
       "7   GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.1...     8\n",
       "8   GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.3...     8\n",
       "9   GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.3...     8\n",
       "10  GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.1...     8\n",
       "11  GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.1...     8\n",
       "12  GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.3...     8\n",
       "13           IMPELLER (주)정원펌프 NO.1 CONDENSER PUMP 3 0    33\n",
       "14  SELF-ALIGNING ROLLER BEARING 대동베아링상사 BOW THRUS...     0\n",
       "15  TAPERED ROLLER BEARING 대동베아링상사 BOW THRUSTER 5....     0\n",
       "16  SELF-ALIGNING ROLLER BEARING 대동베아링상사 BOW THRUS...     0\n",
       "17  TAPERED ROLLER BEARING 대동베아링상사 BOW THRUSTER 7....    14\n",
       "18  EXHUAST GAS TEMP. INDICATOR, P5 PIRIOU NAVAL S...    14\n",
       "19  EXHAUST GAS TEMPERATURE INDICATOR 0 TO 700℃ PI...    14"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a694a2a-3cff-47b1-8c05-d30d50cb99be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text' 'key2']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def preprocess_text(sen):\n",
    "    sentence = remove_tags(sen)\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    return sentence\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "en_text = []\n",
    "sentences = list(df_text['text'])\n",
    "for sen in sentences:\n",
    "    en_text.append(preprocess_text(sen))\n",
    "\n",
    "print(df_text.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bd40d5c-4f5e-4ebf-a48f-e930b433bc33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEAL RING STOR HAEIN Coporation Cheonan NO GENERATOR ENGINE '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d992cd3-dc1e-40d6-a7ab-2abb16ab4d89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df_text.key2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d1d5e47-cada-43bd-acae-6d5cb974dfcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8, 33,  0,  0,  0,\n",
       "       14, 14, 14])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afd34a4a-a2e5-49ec-b9ed-1655d1405901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_categorical = to_categorical(y, num_classes=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18cd8304-3fcd-49fa-bb0b-b1312458a1f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4692f2b4-1194-4d3b-8b26-d199db459753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -y tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16bffe19-c415-4d40-a80e-404697702823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip3 install -U \"tensorflow==2.11.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fd4b60f-090a-4376-8c75-1fb94fda3dcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "D:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\tensorflow\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7ab9103-fa6c-44d8-b7dc-172752e7bf1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n",
    "tokenized_text = [tokenize_text(en) for en in en_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0620ea9e-5219-42ba-bc06-dcb38e7bd3c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최대 길이 : 30\n",
      "문장의 평균 길이 : 11.870191562967936\n"
     ]
    }
   ],
   "source": [
    "print('문장의 최대 길이 :',max(len(l) for l in tokenized_text))\n",
    "print('문장의 평균 길이 :',sum(map(len, tokenized_text))/len(tokenized_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea4f84cb-1f44-4445-8086-dc8053e17ba9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# max_len = 30\n",
    "\n",
    "# tokenized_text = pad_sequences(tokenized_text, maxlen = max_len)\n",
    "# X_test = pad_sequences(X_test, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ce5a187-7ba8-4da4-abc8-a088c2b5d6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('WASHER HAEIN Coporation Cheonan NO GENERATOR ENGINE ',\n",
       " [9378, 2121, 5292, 12377, 8872, 21223, 18178, 7856, 2078, 2053, 13103, 3194])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_text[2],tokenized_text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "577c517f-ad92-48ea-a83d-4ea1a43f2c44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reviews_with_len = [[text, y[i], len(text)] # 토큰화된 text, key값, text 길이\n",
    "#                  for i, text in enumerate(tokenized_text)]\n",
    "# reviews_with_len[:5]\n",
    "\n",
    "reviews_with_len = [[text, y_train_categorical[i], len(text)] # 토큰화된 text, key값, text 길이\n",
    "                 for i, text in enumerate(tokenized_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8830b0b6-ed95-4c00-be05-e53c09251cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[23365, 3796, 3796],\n",
       "  array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "  3],\n",
       " [[11307, 2364, 3194],\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "  3],\n",
       " [[3104, 5658, 4049, 3194],\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "  4],\n",
       " [[3614, 5658, 4049, 3194],\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "  4],\n",
       " [[7682, 5658, 4049, 3194],\n",
       "  array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "  4],\n",
       " [[11503, 7682, 2364, 3194],\n",
       "  array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "  4],\n",
       " [[11503, 7682, 2364, 3194],\n",
       "  array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "  4],\n",
       " [[7744, 5658, 4049, 3194],\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "  4],\n",
       " [[10053, 5658, 4049, 3194],\n",
       "  array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "  4],\n",
       " [[27000, 16215, 8879, 10122],\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "  4]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 섞고 길이 기준으로 정렬\n",
    "import random\n",
    "random.shuffle(reviews_with_len)\n",
    "reviews_with_len.sort(key=lambda x: x[2])\n",
    "reviews_with_len[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07bb61b4-d2b0-49f6-a15b-f7405a7f503d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 4), dtype=int32, numpy=\n",
       " array([[23365,  3796,  3796,     0],\n",
       "        [11307,  2364,  3194,     0],\n",
       "        [ 3104,  5658,  4049,  3194],\n",
       "        [ 3614,  5658,  4049,  3194],\n",
       "        [ 7682,  5658,  4049,  3194],\n",
       "        [11503,  7682,  2364,  3194],\n",
       "        [11503,  7682,  2364,  3194],\n",
       "        [ 7744,  5658,  4049,  3194],\n",
       "        [10053,  5658,  4049,  3194],\n",
       "        [27000, 16215,  8879, 10122],\n",
       "        [16054,  5658,  4049,  3194],\n",
       "        [ 5783,  5658,  4049,  3194],\n",
       "        [ 7744,  5658,  4049,  3194],\n",
       "        [ 7682,  5658,  4049,  3194],\n",
       "        [ 2586,  5658,  4049,  3194],\n",
       "        [14743,  5658,  4049,  3194],\n",
       "        [ 5747,  5658,  4049,  3194],\n",
       "        [ 3614,  5658,  4049,  3194],\n",
       "        [ 9093,  5658,  4049,  3194],\n",
       "        [ 3500,  5658,  4049,  3194],\n",
       "        [11224,  5658,  4049,  3194],\n",
       "        [ 1051,  3614,  2364,  3194],\n",
       "        [17490,  5658,  4049,  3194],\n",
       "        [10764,  5658,  4049,  3194],\n",
       "        [ 5747,  5658,  4049,  3194],\n",
       "        [ 7682,  8722,  2663,  2818],\n",
       "        [16054,  5658,  4049,  3194],\n",
       "        [ 8815,  5658,  4049,  3194],\n",
       "        [ 7682,  5658,  4049,  3194],\n",
       "        [ 7744,  5658,  4049,  3194],\n",
       "        [ 3614,  5658,  4049,  3194],\n",
       "        [ 7744,  5658,  4049,  3194]])>,\n",
       " <tf.Tensor: shape=(32, 43), dtype=int32, numpy=\n",
       " array([[0, 0, 1, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# sorted_text_labels = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len]\n",
    "# processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_text_labels, output_types=(tf.int32, tf.int32))\n",
    "# BATCH_SIZE = 32\n",
    "# batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))\n",
    "# next(iter(batched_dataset))\n",
    "\n",
    "sorted_text_labels = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len if review_lab[0] is not None]\n",
    "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_text_labels, output_types=(tf.int32, tf.int32))\n",
    "BATCH_SIZE = 32\n",
    "padded_shapes = ((None,), (43,))\n",
    "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=padded_shapes)\n",
    "next(iter(batched_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cb20ff8-dc7e-4324-a2a0-5789ebead578",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "TOTAL_BATCHES = math.ceil(len(sorted_text_labels) / BATCH_SIZE)\n",
    "TEST_BATCHES = TOTAL_BATCHES // 10\n",
    "batched_dataset.shuffle(TOTAL_BATCHES)\n",
    "test_data = batched_dataset.take(TEST_BATCHES)\n",
    "train_data = batched_dataset.skip(TEST_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d515ac2-7535-4bb1-8061-648cacec3af2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=(None, None), dtype=tf.int32, name=None), TensorSpec(shape=(None, 43), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "578510c7-5aa2-41ca-ac7c-8e929ee1211a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for inputs, targets in train_data:\n",
    "#     print(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1d7db5f-810f-4eb2-866e-7061524b6ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(606, 60)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_BATCHES, TEST_BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22930b57-8bec-4be1-ac33-56b746519db2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TEXT_MODEL(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dimensions=128,\n",
    "                 cnn_filters=50,\n",
    "                 dnn_units=512,\n",
    "                 model_output_classes=2,\n",
    "                 dropout_rate=0.1,\n",
    "                 training=False,\n",
    "                 name=\"text_model\"):\n",
    "        super(TEXT_MODEL, self).__init__(name=name)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocabulary_size,\n",
    "                                          embedding_dimensions)\n",
    "        self.cnn_layer1 = tf.keras.layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=3,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "\n",
    "        self.lstm = tf.keras.layers.LSTM(128)\n",
    "        \n",
    "        self.pool = tf.keras.layers.GlobalMaxPool1D()\n",
    "        self.dense_1 = tf.keras.layers.Dense(units=dnn_units, activation=\"relu\")\n",
    "        self.last_dense = tf.keras.layers.Dense(units=model_output_classes,\n",
    "                                                activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        l = self.embedding(inputs)\n",
    "        l_1 = self.cnn_layer1(l) \n",
    "        l_1 = self.pool(l_1) \n",
    "\n",
    "        concatenated = tf.concat([l_1], axis=-1) \n",
    "        concatenated = self.dense_1(concatenated)\n",
    "        lstm_output = self.lstm(tf.expand_dims(concatenated, axis=1))\n",
    "        \n",
    "        model_output = self.last_dense(lstm_output)\n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b2b71ae-53a6-44ea-aa06-6c4b9e1e9a43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_LENGTH = len(tokenizer.vocab)\n",
    "EMB_DIM = 100 #200\n",
    "CNN_FILTERS = 50 #100\n",
    "DNN_UNITS = 128 #256\n",
    "OUTPUT_CLASSES = 43\n",
    "DROPOUT_RATE = 0.1 # 0.2\n",
    "NB_EPOCHS = 20\n",
    "VOCAB_LENGTH\n",
    "# 100 50 128 61 0.1 10 =>0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca899cba-5549-4283-9123-2f252e251d29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
    "                        embedding_dimensions=EMB_DIM,\n",
    "                        cnn_filters=CNN_FILTERS,\n",
    "                        dnn_units=DNN_UNITS,\n",
    "                        model_output_classes=OUTPUT_CLASSES,\n",
    "                        dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35450859-2c35-42ec-b5f0-08a21283ccf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if OUTPUT_CLASSES == 2:\n",
    "    text_model.compile(loss=\"binary_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"accuracy\"])\n",
    "else:\n",
    "    text_model.compile(loss=\"categorical_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "text_model.fit(train_data, epochs=NB_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d6493f8-3c5e-457b-b39c-372080979f55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 6ms/step - loss: 0.3823 - categorical_accuracy: 0.9286\n",
      "15번 학습 :  [0.3822622299194336, 0.9286458492279053]\n"
     ]
    }
   ],
   "source": [
    "results = text_model.evaluate(test_data)\n",
    "print(\"15번 학습 : \", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf143ad-c98f-4ba9-a197-1c005d59b133",
   "metadata": {},
   "source": [
    "## pred 는각각 43개 컬럼 라벨에서의 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b1782d4-1a23-4344-b769-e626ac3dcb02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = text_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "133e79f3-84b4-4b45-992f-fc5a7cef3f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920, 43)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e3806-ddde-4b03-8ba1-ba2458981326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d32926-b7d9-4a30-aa61-eb724528a207",
   "metadata": {},
   "source": [
    "# predicted_result 50개의 배치(배치 사이즈 : 32) 데이터 마다 예측 라벨링을 리스트에 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f942e5d-e068-4281-985f-171d08dd1179",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_result = []\n",
    "for j in range(60):\n",
    "    temp=[]\n",
    "    for i in range(32) :   \n",
    "        predicted_class = tf.argmax(pred[i+ j*32]).numpy() ## 가장 높은 확률의 라벨링 데이터를 구함\n",
    "        temp.append(predicted_class)\n",
    "    predicted_result.append(temp)\n",
    "        # print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa175fc-2d4e-41f5-8f1f-ad363c06d7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for lis in predicted_result:\n",
    "    # print(lis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d693f8-3ab6-4a79-990e-cc372cc1a8e9",
   "metadata": {},
   "source": [
    "# true_result : 테스트 데이터에서의 실제 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58bd7f02-f502-4e2b-86b0-53332ea15776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_result =[]\n",
    "for inputs, targets in test_data.take(60):\n",
    "    # 첫 번째 데이터 샘플에 대한 입력(inputs)과 라벨(targets)을 확인\n",
    "\n",
    "    # Convert EagerTensor to numpy array\n",
    "    targets_numpy = np.array(targets)\n",
    "\n",
    "    # Convert numpy array to list\n",
    "    targets_list = targets_numpy.tolist()\n",
    "    true_result.append(targets_list)\n",
    "    # print(\"Targets:\", targets_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491ed6c6-4952-4d46-a51b-2c989fd68d4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for lis in true_result:\n",
    "#     print(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0902f6ac-2b67-424c-8ac4-27d50a75b13b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 원핫 인코딩 사용시에 실행 \n",
    "for lis in true_result:\n",
    "    for i in range(32):\n",
    "        lis[i] = tf.argmax(lis[i]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858e33f6-fd13-4fb3-bf15-e2f21f9a9730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# true_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c1e02e51-dc3c-4a01-b98c-57fc06cacbcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41c47476-8904-4f22-8d80-e0923c6aa0e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8432631106365928\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 score\n",
    "f1 = f1_score([item for sublist in true_result for item in sublist],\n",
    "              [item for sublist in predicted_result for item in sublist], average='macro')\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "436904cb-2551-4a43-adb8-9324afe2a1c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       216\n",
      "           2       0.65      1.00      0.79        11\n",
      "           3       0.99      0.99      0.99       103\n",
      "           4       1.00      1.00      1.00        32\n",
      "           5       0.89      1.00      0.94        17\n",
      "           6       1.00      0.38      0.55         8\n",
      "           7       1.00      0.90      0.95        10\n",
      "           8       0.58      0.65      0.61        17\n",
      "           9       0.94      0.82      0.88        56\n",
      "          10       0.92      0.92      0.92        26\n",
      "          11       1.00      0.97      0.99        36\n",
      "          12       0.72      0.59      0.65        39\n",
      "          13       0.91      0.96      0.94       331\n",
      "          14       0.97      0.80      0.88        49\n",
      "          15       0.96      0.98      0.97        44\n",
      "          16       0.67      0.50      0.57         8\n",
      "          17       1.00      0.33      0.50         3\n",
      "          18       0.87      0.93      0.90        14\n",
      "          19       0.60      0.60      0.60         5\n",
      "          20       1.00      1.00      1.00         9\n",
      "          21       0.74      0.94      0.83        31\n",
      "          22       1.00      1.00      1.00         3\n",
      "          23       1.00      1.00      1.00        10\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       1.00      0.84      0.91        25\n",
      "          27       0.98      1.00      0.99        48\n",
      "          28       0.99      0.94      0.96       271\n",
      "          29       0.94      0.85      0.89        20\n",
      "          30       0.78      0.83      0.80        46\n",
      "          31       0.88      0.96      0.92        24\n",
      "          32       0.98      0.98      0.98        50\n",
      "          33       0.88      1.00      0.94        29\n",
      "          34       0.97      1.00      0.99        73\n",
      "          35       1.00      1.00      1.00        23\n",
      "          36       1.00      1.00      1.00        13\n",
      "          37       0.82      0.98      0.89        41\n",
      "          38       1.00      0.43      0.60         7\n",
      "          39       0.53      0.71      0.61        14\n",
      "          40       0.93      0.88      0.90        84\n",
      "          41       1.00      0.97      0.99        71\n",
      "          42       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.93      1920\n",
      "   macro avg       0.87      0.84      0.84      1920\n",
      "weighted avg       0.93      0.93      0.93      1920\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report([item for sublist in predicted_result for item in sublist],\n",
    "                            [item for sublist in true_result for item in sublist]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
