{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "261a7657-6dcc-4c74-846b-7753ca0445d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4859b907-8e49-4ce1-8d99-fded5eeccd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca2a05c4-57cd-4915-ab36-49aa6b0c6d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34205099-9c8f-4da3-8d26-468721d091db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # GPU 디바이스 목록 가져오기\n",
    "# gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# if len(gpu_devices) > 0:\n",
    "#     print(\"사용 가능한 GPU가 있습니다.\")\n",
    "#     for device in gpu_devices:\n",
    "#         print(\"GPU 디바이스 이름:\", device.name)\n",
    "# else:\n",
    "#     print(\"사용 가능한 GPU가 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fac9baf-fc45-4766-82be-c6d50dfd830e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install bert-for-tf2\n",
    "# !pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8033901a-87dc-42b1-aaf1-2cda85d9d3d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a242748-4045-47c6-8c1c-c61acba156f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/raw_postpro.csv') # 오류가나면 추가해주세요 .encoding = 'cp949'\n",
    "# 컬럼 삭제\n",
    "df = data.drop(['청구서번호','No.',  '선박입고','완료 여부','리드타임_음수제거','청구량','견적','견적수량','견적화폐','견적단가','발주번호','발주','발주수량','발주금액','미입고 기간','리드타임','창고입고','창고입고수량','입고창고','창고출고','창고출고수량','출고선박','출고운반선','선박입고','선박입고수량','완료 여부'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8f79718-2f3e-457a-bbf5-d8394f490994",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_list = ['COMPRESSOR', 'SEAT', 'TURBINE', 'LINE', 'ANODES', 'DAMPER', 'CARD', 'BELT', 'ARM', 'SWITCH',\n",
    " 'CLIP', 'BATTERY', 'ADAPTER', 'TOOL', 'CONTROL', 'BRAKE', 'TRANSFORMER', 'WINCH']\n",
    "df = df[~df['key2'].isin(delete_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e7e51b2-e8d8-48c9-b1a7-0fa03ab9e002",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19367 entries, 0 to 20516\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Subject      19367 non-null  object\n",
      " 1   Machinery    19367 non-null  object\n",
      " 2   Assembly     19367 non-null  object\n",
      " 3   청구품목         19367 non-null  object\n",
      " 4   Part No.1    19367 non-null  object\n",
      " 5   Part No.2    19367 non-null  object\n",
      " 6   key1         19367 non-null  object\n",
      " 7   key2         19367 non-null  object\n",
      " 8   발주처          19367 non-null  object\n",
      " 9   D/T          19367 non-null  object\n",
      " 10  Control No.  19367 non-null  object\n",
      " 11  leadtime     19367 non-null  int64 \n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0ac12f6-2aec-4362-b507-d8db659ddb7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[['청구품목','발주처','Machinery', 'Assembly' , \"key1\",'key2',\"Part No.1\", \"Part No.2\"]]\n",
    "# 'Machinery', 'Assembly', '청구품목', 'Part No.1', 'Part No.2', 'key1', '발주처'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfa338bd-3298-430c-9534-1f8ddc5a391f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoders = {}  # 각 열에 대한 LabelEncoder를 저장하기 위한 딕셔너리\n",
    "columns_to_encode = ['key2']  # 인코딩을 수행할 열의 이름 리스트\n",
    "\n",
    "for column in columns_to_encode:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df[column])\n",
    "    label_encoders[column] = le # 딕셔너리에 저장\n",
    "    df[column+\"_encoded\"] = le.transform(df[column]) # 새로운 encoding 된 컬럼 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd8e6c31-6c1d-46f0-ad58-7ab1ab285a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(['key2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1d21278-dd5e-4229-9b49-159058e996bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19367 entries, 0 to 20516\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   청구품목          19367 non-null  object\n",
      " 1   발주처           19367 non-null  object\n",
      " 2   Machinery     19367 non-null  object\n",
      " 3   Assembly      19367 non-null  object\n",
      " 4   key1          19367 non-null  object\n",
      " 5   Part No.1     19367 non-null  object\n",
      " 6   Part No.2     19367 non-null  object\n",
      " 7   key2_encoded  19367 non-null  int32 \n",
      "dtypes: int32(1), object(7)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1644800d-98cf-459d-9811-a594db7e7bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# text = df[[ '청구품목', '발주처','Machinery', 'Assembly' , \"key1\"]].apply(lambda row: ' '.join(row), axis=1)\n",
    "# df_text = df[['청구품목', '발주처', 'Machinery', 'Assembly']].apply(lambda row: ' '.join(row), axis=1).to_frame(name='text')\n",
    "df_text = df[['청구품목', '발주처','Machinery' , \"Part No.1\", \"Part No.2\"]].apply(lambda row: ' '.join(row), axis=1).to_frame(name='text')\n",
    "df_text['key2'] = df['key2_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed53b922-d2f1-473d-b234-b725c024dd66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>key2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEAL-O-RING-STOR HAEIN Coporation_Cheonan NO.1...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OIL COOLER &amp; LINES HAEIN Coporation_Cheonan NO...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WASHER HAEIN Coporation_Cheonan NO.2 GENERATOR...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOLT-HIGH TEMP HAEIN Coporation_Cheonan NO.1 G...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEAL HAEIN Coporation_Cheonan NO.1 GENERATOR E...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CORE CHARGES FOR CYLINDER PACK AS HAEIN Copora...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PUMP GP-F TFR-REMAN HAEIN Coporation_Cheonan N...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.1...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.3...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.3...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.1...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.1...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.3...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IMPELLER (주)정원펌프 NO.1 CONDENSER PUMP 3 0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SELF-ALIGNING ROLLER BEARING 대동베아링상사 BOW THRUS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TAPERED ROLLER BEARING 대동베아링상사 BOW THRUSTER 5....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SELF-ALIGNING ROLLER BEARING 대동베아링상사 BOW THRUS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TAPERED ROLLER BEARING 대동베아링상사 BOW THRUSTER 7....</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EXHUAST GAS TEMP. INDICATOR, P5 PIRIOU NAVAL S...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EXHAUST GAS TEMPERATURE INDICATOR 0 TO 700℃ PI...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  key2\n",
       "0   SEAL-O-RING-STOR HAEIN Coporation_Cheonan NO.1...     8\n",
       "1   OIL COOLER & LINES HAEIN Coporation_Cheonan NO...     8\n",
       "2   WASHER HAEIN Coporation_Cheonan NO.2 GENERATOR...     8\n",
       "3   BOLT-HIGH TEMP HAEIN Coporation_Cheonan NO.1 G...     8\n",
       "4   SEAL HAEIN Coporation_Cheonan NO.1 GENERATOR E...     8\n",
       "5   CORE CHARGES FOR CYLINDER PACK AS HAEIN Copora...     8\n",
       "6   PUMP GP-F TFR-REMAN HAEIN Coporation_Cheonan N...     8\n",
       "7   GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.1...     8\n",
       "8   GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.3...     8\n",
       "9   GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.3...     8\n",
       "10  GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.1...     8\n",
       "11  GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.1...     8\n",
       "12  GEAR-WTR PUMP DR HAEIN Coporation_Cheonan NO.3...     8\n",
       "13           IMPELLER (주)정원펌프 NO.1 CONDENSER PUMP 3 0    33\n",
       "14  SELF-ALIGNING ROLLER BEARING 대동베아링상사 BOW THRUS...     0\n",
       "15  TAPERED ROLLER BEARING 대동베아링상사 BOW THRUSTER 5....     0\n",
       "16  SELF-ALIGNING ROLLER BEARING 대동베아링상사 BOW THRUS...     0\n",
       "17  TAPERED ROLLER BEARING 대동베아링상사 BOW THRUSTER 7....    14\n",
       "18  EXHUAST GAS TEMP. INDICATOR, P5 PIRIOU NAVAL S...    14\n",
       "19  EXHAUST GAS TEMPERATURE INDICATOR 0 TO 700℃ PI...    14"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a694a2a-3cff-47b1-8c05-d30d50cb99be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text' 'key2']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def preprocess_text(sen):\n",
    "    sentence = remove_tags(sen)\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    return sentence\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "en_text = []\n",
    "sentences = list(df_text['text'])\n",
    "for sen in sentences:\n",
    "    en_text.append(preprocess_text(sen))\n",
    "\n",
    "print(df_text.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bd40d5c-4f5e-4ebf-a48f-e930b433bc33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# en_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d992cd3-dc1e-40d6-a7ab-2abb16ab4d89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df_text.key2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d1d5e47-cada-43bd-acae-6d5cb974dfcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8, 33,  0,  0,  0,\n",
       "       14, 14, 14])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18cd8304-3fcd-49fa-bb0b-b1312458a1f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4692f2b4-1194-4d3b-8b26-d199db459753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -y tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16bffe19-c415-4d40-a80e-404697702823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip3 install -U \"tensorflow==2.11.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fd4b60f-090a-4376-8c75-1fb94fda3dcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "D:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\tensorflow\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7ab9103-fa6c-44d8-b7dc-172752e7bf1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n",
    "tokenized_text = [tokenize_text(en) for en in en_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0620ea9e-5219-42ba-bc06-dcb38e7bd3c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print('문장의 최대 길이 :',max(len(l) for l in tokenized_text))\n",
    "# print('문장의 평균 길이 :',sum(map(len, tokenized_text))/len(tokenized_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea4f84cb-1f44-4445-8086-dc8053e17ba9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# max_len = 30\n",
    "\n",
    "# tokenized_text = pad_sequences(tokenized_text, maxlen = max_len)\n",
    "# X_test = pad_sequences(X_test, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6ce5a187-7ba8-4da4-abc8-a088c2b5d6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('WASHER HAEIN Coporation Cheonan NO GENERATOR ENGINE ',\n",
       " [9378, 2121, 5292, 12377, 8872, 21223, 18178, 7856, 2078, 2053, 13103, 3194])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_text[2],tokenized_text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "577c517f-ad92-48ea-a83d-4ea1a43f2c44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews_with_len = [[text, y[i], len(text)] # 토큰화된 text, key값, text 길이\n",
    "                 for i, text in enumerate(tokenized_text)]\n",
    "# reviews_with_len[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8830b0b6-ed95-4c00-be05-e53c09251cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[11307, 2364, 3194], 12, 3],\n",
       " [[23365, 3796, 3796], 2, 3],\n",
       " [[5009, 5658, 4049, 3194], 40, 4],\n",
       " [[7400, 7682, 2364, 3194], 0, 4],\n",
       " [[8815, 5658, 4049, 3194], 21, 4],\n",
       " [[2303, 5658, 4049, 3194], 8, 4],\n",
       " [[8667, 5658, 4049, 3194], 30, 4],\n",
       " [[16054, 5658, 4049, 3194], 3, 4],\n",
       " [[11307, 5658, 4049, 3194], 12, 4],\n",
       " [[8999, 5658, 4049, 3194], 30, 4]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 섞고 key2 기준으로 정렬\n",
    "import random\n",
    "random.shuffle(reviews_with_len)\n",
    "reviews_with_len.sort(key=lambda x: x[2])\n",
    "reviews_with_len[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07bb61b4-d2b0-49f6-a15b-f7405a7f503d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 4), dtype=int32, numpy=\n",
       " array([[11307,  2364,  3194,     0],\n",
       "        [23365,  3796,  3796,     0],\n",
       "        [ 5009,  5658,  4049,  3194],\n",
       "        [ 7400,  7682,  2364,  3194],\n",
       "        [ 8815,  5658,  4049,  3194],\n",
       "        [ 2303,  5658,  4049,  3194],\n",
       "        [ 8667,  5658,  4049,  3194],\n",
       "        [16054,  5658,  4049,  3194],\n",
       "        [11307,  5658,  4049,  3194],\n",
       "        [ 8999,  5658,  4049,  3194],\n",
       "        [ 1051,  3614,  2364,  3194],\n",
       "        [ 5783,  5658,  4049,  3194],\n",
       "        [13617,  5658,  4049,  3194],\n",
       "        [11503,  7682,  2364,  3194],\n",
       "        [ 2586,  5658,  4049,  3194],\n",
       "        [ 7682,  5658,  4049,  3194],\n",
       "        [ 2686,  2099,  2364,  3194],\n",
       "        [10764, 16215,  8879, 10122],\n",
       "        [17490,  5658,  4049,  3194],\n",
       "        [ 3614,  5658,  4049,  3194],\n",
       "        [ 7682,  5658,  4049,  3194],\n",
       "        [ 1051,  3614,  2364,  3194],\n",
       "        [ 7682,  5658,  4049,  3194],\n",
       "        [ 3104,  5658,  4049,  3194],\n",
       "        [ 8815,  5658,  4049,  3194],\n",
       "        [ 2586,  5658,  4049,  3194],\n",
       "        [16054,  5658,  4049,  3194],\n",
       "        [ 5747,  5658,  4049,  3194],\n",
       "        [16054,  5658,  4049,  3194],\n",
       "        [ 9093,  7744,  9347, 29329],\n",
       "        [ 9093,  5658,  4049,  3194],\n",
       "        [ 3104,  5658,  4049,  3194]])>,\n",
       " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       " array([12,  2, 40,  0, 21,  8, 30,  3, 12, 30, 28, 12, 14,  0, 21,  0, 36,\n",
       "        40, 27, 13,  0, 28,  0,  9, 13, 21,  3,  4,  3, 35, 35,  9])>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sorted_text_labels = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len]\n",
    "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_text_labels, output_types=(tf.int32, tf.int32))\n",
    "BATCH_SIZE = 32\n",
    "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))\n",
    "next(iter(batched_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cb20ff8-dc7e-4324-a2a0-5789ebead578",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "TOTAL_BATCHES = math.ceil(len(sorted_text_labels) / BATCH_SIZE)\n",
    "TEST_BATCHES = TOTAL_BATCHES // 10\n",
    "batched_dataset.shuffle(TOTAL_BATCHES)\n",
    "test_data = batched_dataset.take(TEST_BATCHES)\n",
    "train_data = batched_dataset.skip(TEST_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d515ac2-7535-4bb1-8061-648cacec3af2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=(None, None), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "578510c7-5aa2-41ca-ac7c-8e929ee1211a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for inputs, targets in train_data:\n",
    "#     print(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1d7db5f-810f-4eb2-866e-7061524b6ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(606, 60)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_BATCHES, TEST_BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22930b57-8bec-4be1-ac33-56b746519db2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TEXT_MODEL(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dimensions=128,\n",
    "                 cnn_filters=50,\n",
    "                 dnn_units=512,\n",
    "                 model_output_classes=2,\n",
    "                 dropout_rate=0.1,\n",
    "                 training=False,\n",
    "                 name=\"text_model\"):\n",
    "        super(TEXT_MODEL, self).__init__(name=name)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocabulary_size,\n",
    "                                          embedding_dimensions)\n",
    "        self.cnn_layer1 = tf.keras.layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=3,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "\n",
    "        self.lstm = tf.keras.layers.LSTM(128)\n",
    "        \n",
    "        self.pool = tf.keras.layers.GlobalMaxPool1D()\n",
    "        self.dense_1 = tf.keras.layers.Dense(units=dnn_units, activation=\"relu\")\n",
    "        self.last_dense = tf.keras.layers.Dense(units=model_output_classes,\n",
    "                                                activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        l = self.embedding(inputs)\n",
    "        l_1 = self.cnn_layer1(l) \n",
    "        l_1 = self.pool(l_1) \n",
    "\n",
    "        concatenated = tf.concat([l_1], axis=-1) \n",
    "        concatenated = self.dense_1(concatenated)\n",
    "        lstm_output = self.lstm(tf.expand_dims(concatenated, axis=1))\n",
    "        \n",
    "        model_output = self.last_dense(concatenated)\n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b2b71ae-53a6-44ea-aa06-6c4b9e1e9a43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_LENGTH = len(tokenizer.vocab)\n",
    "EMB_DIM = 100 #200\n",
    "CNN_FILTERS = 50 #100\n",
    "DNN_UNITS = 128 #256\n",
    "OUTPUT_CLASSES = 43\n",
    "DROPOUT_RATE = 0.1 # 0.2\n",
    "NB_EPOCHS = 15\n",
    "VOCAB_LENGTH\n",
    "# 100 50 128 61 0.1 10 =>0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca899cba-5549-4283-9123-2f252e251d29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
    "                        embedding_dimensions=EMB_DIM,\n",
    "                        cnn_filters=CNN_FILTERS,\n",
    "                        dnn_units=DNN_UNITS,\n",
    "                        model_output_classes=OUTPUT_CLASSES,\n",
    "                        dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35450859-2c35-42ec-b5f0-08a21283ccf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['text_model/lstm/lstm_cell/kernel:0', 'text_model/lstm/lstm_cell/recurrent_kernel:0', 'text_model/lstm/lstm_cell/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['text_model/lstm/lstm_cell/kernel:0', 'text_model/lstm/lstm_cell/recurrent_kernel:0', 'text_model/lstm/lstm_cell/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['text_model/lstm/lstm_cell/kernel:0', 'text_model/lstm/lstm_cell/recurrent_kernel:0', 'text_model/lstm/lstm_cell/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['text_model/lstm/lstm_cell/kernel:0', 'text_model/lstm/lstm_cell/recurrent_kernel:0', 'text_model/lstm/lstm_cell/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546/546 [==============================] - 7s 8ms/step - loss: 2.0750 - sparse_categorical_accuracy: 0.5061\n",
      "Epoch 2/30\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 1.0687 - sparse_categorical_accuracy: 0.7507\n",
      "Epoch 3/30\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.8488 - sparse_categorical_accuracy: 0.7945\n",
      "Epoch 4/30\n",
      "546/546 [==============================] - 3s 6ms/step - loss: 0.7657 - sparse_categorical_accuracy: 0.8109\n",
      "Epoch 5/30\n",
      "546/546 [==============================] - 3s 6ms/step - loss: 0.7174 - sparse_categorical_accuracy: 0.8199\n",
      "Epoch 6/30\n",
      "546/546 [==============================] - 3s 6ms/step - loss: 0.6827 - sparse_categorical_accuracy: 0.8256\n",
      "Epoch 7/30\n",
      "546/546 [==============================] - 3s 6ms/step - loss: 0.6573 - sparse_categorical_accuracy: 0.8307\n",
      "Epoch 8/30\n",
      "546/546 [==============================] - 3s 6ms/step - loss: 0.6367 - sparse_categorical_accuracy: 0.8320\n",
      "Epoch 9/30\n",
      "546/546 [==============================] - 7s 13ms/step - loss: 0.6203 - sparse_categorical_accuracy: 0.8355\n",
      "Epoch 10/30\n",
      "546/546 [==============================] - 15s 27ms/step - loss: 0.6062 - sparse_categorical_accuracy: 0.8375\n",
      "Epoch 11/30\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5938 - sparse_categorical_accuracy: 0.8395\n",
      "Epoch 12/30\n",
      "546/546 [==============================] - 14s 25ms/step - loss: 0.5826 - sparse_categorical_accuracy: 0.8413\n",
      "Epoch 13/30\n",
      "546/546 [==============================] - 14s 25ms/step - loss: 0.5742 - sparse_categorical_accuracy: 0.8431\n",
      "Epoch 14/30\n",
      "546/546 [==============================] - 15s 27ms/step - loss: 0.5649 - sparse_categorical_accuracy: 0.8433\n",
      "Epoch 15/30\n",
      " 10/546 [..............................] - ETA: 9s - loss: 0.0159 - sparse_categorical_accuracy: 0.9969 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     text_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m                        optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m                        metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtext_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNB_EPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mD:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32mD:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mD:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mD:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mD:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mD:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mD:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if OUTPUT_CLASSES == 2:\n",
    "    text_model.compile(loss=\"binary_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"accuracy\"])\n",
    "else:\n",
    "    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "text_model.fit(train_data, epochs=NB_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d6493f8-3c5e-457b-b39c-372080979f55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 6ms/step - loss: 0.3020 - sparse_categorical_accuracy: 0.9385\n",
      "30번 학습 :  [0.3020440340042114, 0.9385416507720947]\n"
     ]
    }
   ],
   "source": [
    "results = text_model.evaluate(test_data)\n",
    "print(\"15번 학습 : \", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf143ad-c98f-4ba9-a197-1c005d59b133",
   "metadata": {},
   "source": [
    "## pred 는각각 61개 컬럼 라벨에서의 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b1782d4-1a23-4344-b769-e626ac3dcb02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = text_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "133e79f3-84b4-4b45-992f-fc5a7cef3f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920, 43)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e3806-ddde-4b03-8ba1-ba2458981326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d32926-b7d9-4a30-aa61-eb724528a207",
   "metadata": {},
   "source": [
    "# predicted_result 50개의 배치(배치 사이즈 : 32) 데이터 마다 예측 라벨링을 리스트에 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f942e5d-e068-4281-985f-171d08dd1179",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_result = []\n",
    "for j in range(60):\n",
    "    temp=[]\n",
    "    for i in range(32) :   \n",
    "        predicted_class = tf.argmax(pred[i+ j*32]).numpy() ## 가장 높은 확률의 라벨링 데이터를 구함\n",
    "        temp.append(predicted_class)\n",
    "    predicted_result.append(temp)\n",
    "        # print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa175fc-2d4e-41f5-8f1f-ad363c06d7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for lis in predicted_result:\n",
    "#     print(lis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d693f8-3ab6-4a79-990e-cc372cc1a8e9",
   "metadata": {},
   "source": [
    "# true_result : 테스트 데이터에서의 실제 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58bd7f02-f502-4e2b-86b0-53332ea15776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_result =[]\n",
    "for inputs, targets in test_data.take(60):\n",
    "    # 첫 번째 데이터 샘플에 대한 입력(inputs)과 라벨(targets)을 확인\n",
    "\n",
    "    # Convert EagerTensor to numpy array\n",
    "    targets_numpy = np.array(targets)\n",
    "\n",
    "    # Convert numpy array to list\n",
    "    targets_list = targets_numpy.tolist()\n",
    "    true_result.append(targets_list)\n",
    "    # print(\"Targets:\", targets_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491ed6c6-4952-4d46-a51b-2c989fd68d4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for lis in true_result:\n",
    "#     print(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1e02e51-dc3c-4a01-b98c-57fc06cacbcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41c47476-8904-4f22-8d80-e0923c6aa0e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8820806912370188\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 score\n",
    "f1 = f1_score([item for sublist in true_result for item in sublist],\n",
    "              [item for sublist in predicted_result for item in sublist], average='macro')\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7056a6b9-d8f4-4970-8531-684f4ca15cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       217\n",
      "           2       0.89      1.00      0.94        16\n",
      "           3       0.99      0.99      0.99       101\n",
      "           4       1.00      0.97      0.99        39\n",
      "           5       0.94      0.89      0.91        18\n",
      "           6       1.00      0.67      0.80         3\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       0.72      0.87      0.79        15\n",
      "           9       0.96      0.94      0.95        49\n",
      "          10       0.93      0.87      0.90        30\n",
      "          11       1.00      0.94      0.97        36\n",
      "          12       0.96      0.72      0.83        36\n",
      "          13       0.90      0.98      0.94       319\n",
      "          14       0.97      0.97      0.97        39\n",
      "          15       0.95      0.89      0.92        47\n",
      "          16       0.67      1.00      0.80         4\n",
      "          17       1.00      1.00      1.00         1\n",
      "          18       0.80      1.00      0.89        12\n",
      "          19       0.40      0.18      0.25        11\n",
      "          20       1.00      0.91      0.95        11\n",
      "          21       0.76      0.94      0.84        31\n",
      "          22       1.00      1.00      1.00         1\n",
      "          23       1.00      0.67      0.80        15\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       1.00      0.95      0.98        22\n",
      "          27       1.00      1.00      1.00        50\n",
      "          28       0.98      0.92      0.95       264\n",
      "          29       0.95      1.00      0.97        19\n",
      "          30       0.79      1.00      0.88        37\n",
      "          31       1.00      0.93      0.96        28\n",
      "          32       0.98      0.83      0.90        66\n",
      "          33       0.97      0.92      0.94        37\n",
      "          34       0.97      1.00      0.99        76\n",
      "          35       1.00      0.92      0.96        25\n",
      "          36       1.00      0.94      0.97        18\n",
      "          37       0.81      1.00      0.89        38\n",
      "          38       1.00      1.00      1.00         5\n",
      "          39       0.35      0.70      0.47        10\n",
      "          40       0.95      0.84      0.89        85\n",
      "          41       1.00      0.99      0.99        81\n",
      "          42       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.94      1920\n",
      "   macro avg       0.89      0.89      0.88      1920\n",
      "weighted avg       0.94      0.94      0.94      1920\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\ShipSupplies\\DA\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report([item for sublist in predicted_result for item in sublist],\n",
    "                            [item for sublist in true_result for item in sublist]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
