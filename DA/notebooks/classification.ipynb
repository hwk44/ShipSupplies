{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1366c7ef-ab33-46a1-a42e-752ba52ceb90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d213c00f-cf6b-4163-9c4d-7edfa03ed7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw_postpro.csv')\n",
    "# df.head()\n",
    "# df2 = df[[\"Machinery\", 'Assembly']]\n",
    "# df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f5d6238-eb85-4b15-b60d-aa8b6acff1d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sns.countplot(x='key2', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c14f57e6-3315-412b-bf58-d0fd5305a4b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df['key2'].mode()\n",
    "# grouped_df = df.groupby('key2')\n",
    "# grouped_df.head()\n",
    "# grouped_df[['Subject','Machinery', 'Assembly', '청구품목']].head()\n",
    "# series1 = grouped_df['청구서번호'].count()\n",
    "# series1.iloc[:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8717f36-5bf9-4991-bef5-b54328819684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# plt.bar(grouped_df['청구서번호'].count().index,grouped_df['청구서번호'].count())\n",
    "# plt.xlabel(\"key2\")\n",
    "# plt.ylabel('count')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.ylim(500,4200)\n",
    "# # 특정 품목만 많이 청구됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04c6bf33-811f-4a3a-b915-0ef020a94b40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "df = df.apply(le.fit_transform)\n",
    "\n",
    "X = df[['Machinery', 'Assembly' , \"Part No.1\",\"청구품목\"]]\n",
    "y = df[\"key2\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=40, shuffle=True, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "839cd159",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Machinery</th>\n",
       "      <th>Assembly</th>\n",
       "      <th>Part No.1</th>\n",
       "      <th>청구품목</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26</td>\n",
       "      <td>1390</td>\n",
       "      <td>4821</td>\n",
       "      <td>5510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>26</td>\n",
       "      <td>1390</td>\n",
       "      <td>5134</td>\n",
       "      <td>4916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26</td>\n",
       "      <td>1390</td>\n",
       "      <td>5760</td>\n",
       "      <td>5510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>148</td>\n",
       "      <td>1248</td>\n",
       "      <td>1703</td>\n",
       "      <td>1899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>148</td>\n",
       "      <td>1248</td>\n",
       "      <td>1703</td>\n",
       "      <td>1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>148</td>\n",
       "      <td>1248</td>\n",
       "      <td>1833</td>\n",
       "      <td>2544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Machinery  Assembly  Part No.1  청구품목\n",
       "15         26      1390       4821  5510\n",
       "16         26      1390       5134  4916\n",
       "17         26      1390       5760  5510\n",
       "18        148      1248       1703  1899\n",
       "19        148      1248       1703  1887\n",
       "20        148      1248       1833  2544"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[15:21,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d65329da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15     4\n",
       "16     4\n",
       "17    25\n",
       "18    25\n",
       "19    25\n",
       "20    25\n",
       "Name: key2, dtype: int32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[15:21]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e610dab2-4672-4d45-bfd4-27c0eb9307ee",
   "metadata": {},
   "source": [
    "# CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5314d7e1-d92c-487a-a899-2a5d918cf5de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    " \n",
    "rng = np.random.RandomState(100)\n",
    "clf = CategoricalNB(alpha=0.1).fit(X_train, y_train) \n",
    "## alpha : Laplace Smoothing 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d96fa09a-2e62-48d6-abdf-59dd097be1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 33, 45, ..., 40, 50, 57])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c3222af-d0b7-424f-9f4b-7e53c9a89c05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1, 'class_prior': None, 'fit_prior': True, 'force_alpha': 'warn', 'min_categories': None}\n",
      "정확도 :  0.968561506123195\n",
      "정확도 :  0.7775341130604289\n"
     ]
    }
   ],
   "source": [
    "print(clf.get_params()) ## CategoricalNB 클래스 인자 설정 정보\n",
    "print('정확도 : ', clf.score(X_train,y_train)) ## 성능 평가 점수(Accuracy\n",
    "print('정확도 : ', clf.score(X_test,y_test)) ## 성능 평가 점수(Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c05ba09-f341-4687-8d62-0e74156745ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968561506123195"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23f5c0d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  36.343276307452356\n",
      "F1-score: 0.779383691454742\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "# 모델 평가\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "y_pred = clf.predict(X)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "\n",
    "\n",
    "# 모델 예측\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# mse 값 계산\n",
    "print(\"MSE: \", mse)\n",
    "\n",
    "# F1-score 계산\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57da5b6",
   "metadata": {},
   "source": [
    "# OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13886bb6-b564-456d-96dd-fe494e9523ed",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93398934",
   "metadata": {},
   "source": [
    "## Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "688c9e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/raw_postpro.csv')\n",
    "\n",
    "df = df.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "X = df[['Machinery', 'Assembly' , \"Part No.1\",\"청구품목\"]]\n",
    "y = df[\"key2\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=40, shuffle=True, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87aee0d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도 : 0.974\n",
      "테스트 세트 정확도 : 0.755\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=24, random_state= 0) # 트리 생성\n",
    "tree.fit(X_train, y_train)\n",
    "print(\"훈련 세트 정확도 : {:.3f}\".format(tree.score(X_train,y_train)))\n",
    "print(\"테스트 세트 정확도 : {:.3f}\".format(tree.score(X_test,y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "554d1c65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.7540515071387015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 모델 예측\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "# F1-score 계산\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501dad98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a4425f8",
   "metadata": {},
   "source": [
    "## Xgboost : softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a821c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8450292397660819\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 학습 데이터와 테스트 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# xgboost 모델 생성\n",
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=61)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측 결과 출력\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4c06595",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.843450153794426\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 모델 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# F1-score 계산\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e6152d-3544-4d83-9f81-c097198a77a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd9d12e-9639-4428-b1c9-fc56f3e0dfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e9df889-9615-41b1-a6d2-6479f67e6906",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eff4d64c-c4ee-4300-9e67-4b8a937100ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 텍스트 데이터\n",
    "df = pd.read_csv('../data/raw_postpro.csv')\n",
    "X = list(df['Machinery']  + ' ' + df['Assembly'] + ' ' + df['청구품목'] + ' ' + df['Part No.1'])\n",
    "y = df[\"key2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02a5edfd-0e18-4cf6-a9b4-6e5d71018f46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CountVectorizer를 이용하여 feature 벡터 생성\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3d14497-2ae3-4ddf-b772-231aa1b78991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y 값을 숫자로 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92505d45-cc97-45a8-8654-936e4901b3d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8581871345029239\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터와 테스트 데이터 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# xgboost 모델 생성\n",
    "model = XGBClassifier(objective='multi:softmax', num_class=61)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측 결과 출력\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6026e633-0b90-4f1f-8352-2d3dd0d49c60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score\n",
    "def print_metrics(y_test, X_test, model) :\n",
    "  # 테스트 데이터셋으로 예측\n",
    "  y_pred = model.predict(X_test)\n",
    "\n",
    "  # 각종 평가지표 계산\n",
    "  recall = recall_score(y_test, y_pred, average='macro')\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  precision = precision_score(y_test, y_pred, average='macro')\n",
    "  f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "  print(\"Recall: {:.4f}\".format(recall))\n",
    "  print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "  print(\"Precision: {:.4f}\".format(precision))\n",
    "  print(\"F1-score: {:.4f}\".format(f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffdeaf69-e8e0-4176-b0f8-a72abe0c1c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.8235\n",
      "Accuracy: 0.8582\n",
      "Precision: 0.8675\n",
      "F1-score: 0.8404\n"
     ]
    }
   ],
   "source": [
    " print_metrics(y_test, X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c4101b-8eee-4703-afe5-725b3b18a0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d518e991-488b-4360-93bf-6592fbf916b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ea54b87-7216-4d22-affe-5dde0022bedf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Found existing installation: tensorflow 2.12.0\n",
      "Uninstalling tensorflow-2.12.0:\n",
      "  Would remove:\n",
      "    d:\\shipsupplies\\venv\\lib\\site-packages\\tensorflow-2.12.0.dist-info\\*\n",
      "Proceed (Y/n)? \n"
     ]
    }
   ],
   "source": [
    "!pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f3aa96d-ff95-452a-b5b4-03fc09bb7903",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\shipsupplies\\venv\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.23.2)\n",
      "Requirement already satisfied: setuptools in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.54.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\shipsupplies\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in d:\\shipsupplies\\venv\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: scipy>=1.7 in d:\\shipsupplies\\venv\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\shipsupplies\\venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\shipsupplies\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\shipsupplies\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\shipsupplies\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\shipsupplies\\venv\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\shipsupplies\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\shipsupplies\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\shipsupplies\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\shipsupplies\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\shipsupplies\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in d:\\shipsupplies\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\shipsupplies\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\shipsupplies\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\shipsupplies\\venv\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0388366c-9346-44e0-b675-2b8a0f9653c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorFlow version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb28f0c7-a284-47fe-b17f-56b18efe885f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0c99f5f-08c6-49fa-a955-36ac9de3e2ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text_to_word_sequence\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 4개 컬럼을 하나의 문자열로 합치기\u001b[39;00m\n\u001b[0;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMachinery\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAssembly\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m청구품목\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPart No.1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "# 4개 컬럼을 하나의 문자열로 합치기\n",
    "data = df['Machinery'] + ' ' + df['Assembly'] + ' ' + df['청구품목'] + ' ' + df['Part No.1']\n",
    "\n",
    "# 문장 토큰화\n",
    "sentences = [text_to_word_sequence(sentence) for sentence in data]\n",
    "\n",
    "# Word2Vec 모델 학습\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4) # 벡터사이즈 100\n",
    "\n",
    "# 단어 임베딩 활용\n",
    "embedded_data = []\n",
    "for sentence in sentences:\n",
    "    embedded_sentence = [model.wv[word] for word in sentence]\n",
    "    embedded_data.append(embedded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "197a36a5-052a-4760-9ce0-2d2e27e66a35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 긴 문장의 길이: 28\n"
     ]
    }
   ],
   "source": [
    "# embedded_data\n",
    "# 문장들의 길이 확인\n",
    "sentence_lengths = [len(sentence) for sentence in embedded_data]\n",
    "\n",
    "# 가장 긴 문장의 길이 확인\n",
    "max_sequence_length = max(sentence_lengths)\n",
    "\n",
    "print(\"가장 긴 문장의 길이:\", max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "35e26399-81b6-4866-adde-9d0b37318cce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y 값을 숫자로 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2da81bb4-eab7-4291-b309-02c4ba8e0344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "757df94c-7d65-4fce-b8c3-ac0396357b30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train, test 데이터 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(embedded_data, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "faca0b5b-5837-4114-813a-62c2ffd36dba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342161c0-b2fa-4b93-81eb-5487971dc9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c637e5db-ba16-40c0-a10c-e61d18702dc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in d:\\shipsupplies\\venv\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in d:\\shipsupplies\\venv\\lib\\site-packages (from scipy) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0e37efff-7184-4351-bf17-95a7a57156e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SW\\AppData\\Local\\Temp\\ipykernel_4048\\2722629460.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train_array = np.array(X_train)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 34\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# X_train과 y_train 데이터의 인덱스 정렬\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# X_train_sorted = tf.sparse.reorder(tf.sparse.SparseTensor((X_train_sparse.row, X_train_sparse.col), X_train_sparse.data, X_train_sparse.shape))\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# y_train_sorted = tf.sparse.reorder(tf.sparse.SparseTensor((y_train_sparse.row, y_train_sparse.col), y_train_sparse.data, y_train_sparse.shape))\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# 모델 컴파일 및 학습\u001b[39;00m\n\u001b[0;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_sparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ShipSupplies\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\ShipSupplies\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import pandas as pd\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(28, 100))) # 벡터사이즈 = embedding_dimension 100\n",
    "model.add(Dense(1))\n",
    "\n",
    "import tensorflow as tf\n",
    "from scipy.sparse import coo_matrix\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# X_train과 y_train을 넘파이 배열로 변환\n",
    "X_train_array = np.array(X_train)\n",
    "y_train_array = np.array(y_train)\n",
    "\n",
    "# X_train과 y_train 데이터를 희소 행렬로 변환\n",
    "X_train_sparse = coo_matrix(X_train_array)\n",
    "y_train_sparse = coo_matrix(y_train_array)\n",
    "# 모델 정의\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train_sparse.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# X_train과 y_train 데이터의 인덱스 정렬\n",
    "# X_train_sorted = tf.sparse.reorder(tf.sparse.SparseTensor((X_train_sparse.row, X_train_sparse.col), X_train_sparse.data, X_train_sparse.shape))\n",
    "# y_train_sorted = tf.sparse.reorder(tf.sparse.SparseTensor((y_train_sparse.row, y_train_sparse.col), y_train_sparse.data, y_train_sparse.shape))\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train_sparse, y_train_sparse.toarray(), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33e08973-1f27-4c4a-8cf3-4a7b82c3c9df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m sorted_predictions \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mreorder(\u001b[43mpredictions\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sorted_predictions = tf.sparse.reorder(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1d69b7-bf17-4b7c-a184-e955224a1f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37fc886a-f261-4726-87b3-5b209c1b3894",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.8636\n",
      "Accuracy: 0.9040\n",
      "Precision: 0.9209\n",
      "F1-score: 0.8832\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression 모델 생성 및 학습\n",
    "lr = LogisticRegression(random_state=42, C=14, solver=\"liblinear\", penalty='l1', multi_class=\"ovr\", max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "lr_acc = accuracy_score(y_test, lr_pred)\n",
    "print_metrics(y_test, X_test, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5263fe2b-322f-4415-85ae-c4cbd3339aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8069341-7466-4f7f-b0d7-6a406794392a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score\n",
    "def print_metrics(y_test, X_test, model) :\n",
    "  # 테스트 데이터셋으로 예측\n",
    "  y_pred = model.predict(X_test)\n",
    "\n",
    "  # 각종 평가지표 계산\n",
    "  recall = recall_score(y_test, y_pred, average='macro')\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  precision = precision_score(y_test, y_pred, average='macro')\n",
    "  f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "  print(\"Recall: {:.4f}\".format(recall))\n",
    "  print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "  print(\"Precision: {:.4f}\".format(precision))\n",
    "  print(\"F1-score: {:.4f}\".format(f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77142f61-dbff-4229-a2bb-1a98bbb9c100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24199b8c-af29-4b4d-bdc4-7d3c9da7327c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ff2856-baa8-4aa2-9bf4-a8b5bb934145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10410b1c-565e-4cf9-aa2d-ab89f0032324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
